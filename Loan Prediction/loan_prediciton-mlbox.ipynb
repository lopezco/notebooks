{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "hackathon source = https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem Statement\n",
    "### About Company\n",
    "Dream Housing Finance company deals in all home loans. They have presence across all urban, semi urban and rural areas. Customer first apply for home loan after that company validates the customer eligibility for loan.\n",
    "\n",
    "### Problem\n",
    "Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers. Here they have provided a partial data set.\n",
    "\n",
    "## Data\n",
    "\n",
    "**Variable**         |**Description**\n",
    ":--------------------|:------------------------\n",
    "Loan_ID              |Unique Loan ID\n",
    "Gender               |Male/ Female\n",
    "Married              |Applicant married (Y/N)\n",
    "Dependents           |Number of dependents\n",
    "Education            |Applicant Education (Graduate/ Under Graduate)\n",
    "Self_Employed        |Self employed (Y/N)\n",
    "ApplicantIncome      |Applicant income\n",
    "CoapplicantIncome    |Coapplicant income\n",
    "LoanAmount           |Loan amount in thousands\n",
    "Loan_Amount_Term     |Term of loan in months\n",
    "Credit_History       |Credit history meets guidelines\n",
    "Property_Area        |Urban/ Semi Urban/ Rural\n",
    "Loan_Status          |Loan approved (Y/N)\n",
    " \n",
    "\n",
    "**Note:**\n",
    "\n",
    "Evaluation Metric is accuracy i.e. percentage of loan approval you correctly predict.\n",
    "You are expected to upload the solutionin a csv file with the following format:\n",
    "\n",
    "Loan_ID | Loan_Status\n",
    ":------:|:------------:\n",
    "LP001002|1\n",
    "LP001003|0\n",
    "...     |...\n",
    "LP001010|1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import csv\n",
    "import zipfile\n",
    "\n",
    "from mlbox.preprocessing import *\n",
    "from mlbox.optimisation import *\n",
    "from mlbox.prediction import *\n",
    "\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, all you need to give is :\n",
    "\n",
    "* The list of paths to your train datasets and test datasets\n",
    "* The name of the target you try to predict (classification or regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the list of paths to your train datasets and test datasets\n",
    "train_data_path = \"./data/train.csv\"\n",
    "test_data_path = \"./data/test.csv\"\n",
    "paths = [train_data_path, test_data_path]\n",
    "\n",
    "# the name of the target you try to predict (classification or regression)\n",
    "target_name = \"Loan_Status\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let the MLBox do the job !\n",
    "\n",
    "... to read and preprocess your files :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading csv : train.csv ...\n",
      "cleaning data...\n",
      "CPU time: 0.09733867645263672 seconds\n",
      "\n",
      "reading csv : test.csv ...\n",
      "cleaning data...\n",
      "CPU time: 0.06172466278076172 seconds\n",
      "\n",
      "number of common features : 12\n",
      "\n",
      "Gathering and crunching for train and test datasets\n",
      "reindexing for train and test datasets\n",
      "Dropping training duplicates\n",
      "Dropping constant variables on training set\n",
      "\n",
      "number of categorical features: 7\n",
      "number of numerical features: 5\n",
      "number of training samples : 614\n",
      "number of test samples : 367\n",
      "\n",
      "Top sparse features (% missing values on train set):\n",
      "Credit_History      8.1\n",
      "Self_Employed       5.2\n",
      "LoanAmount          3.6\n",
      "Dependents          2.4\n",
      "Loan_Amount_Term    2.3\n",
      "dtype: float64\n",
      "\n",
      "task : classification\n",
      "Y    422\n",
      "N    192\n",
      "Name: Loan_Status, dtype: int64\n",
      "encoding target\n"
     ]
    }
   ],
   "source": [
    "# Reading\n",
    "reader = Reader(sep=\",\")\n",
    "data = reader.train_test_split(paths, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing drifts...\n",
      "CPU time: 0.5722939968109131 seconds\n",
      "\n",
      "Top 10 drifts\n",
      "\n",
      "('Loan_ID', 0.99837133550488599)\n",
      "('Property_Area', 0.061928332571045575)\n",
      "('Loan_Amount_Term', 0.054074882580603223)\n",
      "('ApplicantIncome', 0.036496217969404832)\n",
      "('Married', 0.027678590084996957)\n",
      "('Dependents', 0.024188221609812377)\n",
      "('LoanAmount', 0.023957261970819488)\n",
      "('Education', 0.0222398896269278)\n",
      "('Self_Employed', 0.02163707287702854)\n",
      "('Credit_History', 0.013384582672619549)\n",
      "\n",
      "deleted variables : ['Loan_ID']\n",
      "\n",
      "dumping drift coefficients into directory : save\n",
      "drift coefficients dumped\n"
     ]
    }
   ],
   "source": [
    "# Deleting non-stable variables\n",
    "dft = Drift_thresholder()\n",
    "data = dft.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... to evaluate models (here default configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:78: UserWarning: Optimiser will save all your fitted models into directory 'save/joblib'. Please clear it regularly.\n",
      "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parameters set. Default configuration is tested\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 500, 'strategy': 'LightGBM', 'objective': 'binary', 'reg_lambda': 0, 'subsample_for_bin': 50000, 'nthread': -1, 'subsample_freq': 1, 'min_child_weight': 5, 'max_bin': 255, 'reg_alpha': 0, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': -1, 'colsample_bytree': 0.8, 'learning_rate': 0.05, 'subsample': 0.9, 'seed': 0}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.786625219193\n",
      "VARIANCE : 0.0104443613238 (fold 1 = 0.8, fold 2 = 0.785365853659, fold 3 = 0.774509803922)\n",
      "CPU time: 0.6081538200378418 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78662521919336836"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Optimiser(scoring='accuracy', n_folds=3)\n",
    "opt.evaluate(None, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or to test and optimize the whole Pipeline [OPTIONAL]:\n",
    "\n",
    "* missing data encoder, aka 'ne'\n",
    "* categorical variables encoder, aka 'ce'\n",
    "* feature selector, aka 'fs'\n",
    "* meta-features stacker, aka 'stck'\n",
    "* final estimator, aka 'est'\n",
    "\n",
    "**NB :** please have a look at all the possibilities you have to configure the Pipeline (steps, parameters and values...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'median', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'dummification'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.22713757311709015, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 500, 'subsample': 0.7447825107234776, 'objective': 'binary', 'reg_lambda': 2.541249402892196, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 1.8658936341420629, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 3, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.025247749572769422}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.041673898696899414 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'median', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.05722382929028939, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 1250, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 3.366314727755151, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 5.711915452099014, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 7, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.09190500834630261, 'strategy': 'XGBoost', 'subsample': 0.8060409253001002}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.04008603096008301 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.08184140112817802, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.7700867953369583, 'objective': 'binary', 'reg_lambda': 4.5761846101385615, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 6.306466101681877, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.09647945064947344}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 0.5282537937164307 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.09431270346977093, 'strategy': 'variance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 1250, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 3.8484490045833617, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 3.746262296919202, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 3, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.05817750270255482, 'strategy': 'XGBoost', 'subsample': 0.7161048279209402}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.7020859718322754 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'median', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.24593036277589123, 'strategy': 'variance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 500, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 4.4147371649168505, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 1.6964416776846547, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 6, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.05508401290894584, 'strategy': 'XGBoost', 'subsample': 0.6151477349242029}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.0390317440032959 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.2432310494321893, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 1000, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 2.842866431717198, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 3.741245138513527, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 3, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.09173477635732236, 'strategy': 'XGBoost', 'subsample': 0.6611568722082876}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.0534052848815918 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.2868268030687029, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 1250, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 3.5988956984547995, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 0.17220101124028608, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 7, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.09903907384084694, 'strategy': 'XGBoost', 'subsample': 0.7388129314695473}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.0578916072845459 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'dummification'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.24603993170089136, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.6155982585629858, 'objective': 'binary', 'reg_lambda': 6.650377736846639, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 7.665978514761838, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 7, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.07675234970654092}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.06938624382019043 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'median', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.16374247330364972, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 1000, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 4.171580163840548, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 6.008252671310078, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 3, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.05162633572516918, 'strategy': 'XGBoost', 'subsample': 0.4338052632993037}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.0540461540222168 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'median', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.2973833412120263, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 1500, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 9.492074442834092, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 9.804735439461453, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 5, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.06493617093798454, 'strategy': 'XGBoost', 'subsample': 0.6101165788630152}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.03798103332519531 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.1425188319905632, 'strategy': 'variance'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.8831816687153338, 'objective': 'binary', 'reg_lambda': 3.02919549915298, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 1.0859565330130216, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 3, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.094740942268695}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.723051171688\n",
      "VARIANCE : 0.0338870133013 (fold 1 = 0.756097560976, fold 2 = 0.736585365854, fold 3 = 0.676470588235)\n",
      "CPU time: 1.1261484622955322 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'dummification'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.20899063104363372, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 500, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 5.4530040564909745, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 5.9736385170205155, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 5, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.0923323070367907, 'strategy': 'XGBoost', 'subsample': 0.5180871703222965}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.05319952964782715 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'median', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.09204871464558245, 'strategy': 'variance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 1500, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 6.19158651078002, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 3.306272549304138, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 6, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.04613210586744575, 'strategy': 'XGBoost', 'subsample': 0.4882544793506741}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.016387462615966797 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'median', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.05712443140125797, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 500, 'subsample': 0.5551990261955784, 'objective': 'binary', 'reg_lambda': 1.9385672968272505, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 7.862488843461289, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 4, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.04876393373232368}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.047647953033447266 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.16403773177157624, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.6159088540922673, 'objective': 'binary', 'reg_lambda': 3.2644669444975936, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 9.182064186904602, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 7, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.012153279922725276}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 0.820019006729126 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'dummification'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.21680296303793548, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 1000, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 9.685892387270979, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 3.8790664347345927, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 5, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.08754207159528556, 'strategy': 'XGBoost', 'subsample': 0.5431372577754134}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.711637175195\n",
      "VARIANCE : 0.0411636717118 (fold 1 = 0.756097560976, fold 2 = 0.721951219512, fold 3 = 0.656862745098)\n",
      "CPU time: 3.6278138160705566 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'median', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.15240724015856072, 'strategy': 'variance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'missing': None, 'n_estimators': 1500, 'seed': 0, 'objective': 'binary:logistic', 'reg_lambda': 2.4317846065788853, 'scale_pos_weight': 1, 'max_delta_step': 0, 'reg_alpha': 8.202863594958956, 'nthread': -1, 'min_child_weight': 1, 'base_score': 0.5, 'max_depth': 6, 'colsample_bylevel': 1.0, 'gamma': 0, 'colsample_bytree': 0.8, 'learning_rate': 0.04260541846617747, 'strategy': 'XGBoost', 'subsample': 0.46421109975240776}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.018369674682617188 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'dummification'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.2930915913691587, 'strategy': 'variance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1500, 'subsample': 0.5173038935733588, 'objective': 'binary', 'reg_lambda': 4.089038950205203, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 5.683021071755173, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.05009007866064983}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.561485732504\n",
      "VARIANCE : 0.175204265723 (fold 1 = 0.682926829268, fold 2 = 0.687804878049, fold 3 = 0.313725490196)\n",
      "CPU time: 0.928257942199707 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.05203350316620132, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 500, 'subsample': 0.5814294955352006, 'objective': 'binary', 'reg_lambda': 4.625659533838981, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 8.290747273892318, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 7, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.07724077547830725}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.04687666893005371 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'median', 'categorical_strategy': None}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.19045464827907632, 'strategy': 'variance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1500, 'subsample': 0.764298430373314, 'objective': 'binary', 'reg_lambda': 6.992676000024256, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 8.472661401583537, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 7, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.06927696655236949}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = -inf\n",
      "VARIANCE : nan (fold 1 = -inf, fold 2 = -inf, fold 3 = -inf)\n",
      "CPU time: 0.018007993698120117 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.013256151403018362, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.8373489873392056, 'objective': 'binary', 'reg_lambda': 0.5791496760893438, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 9.389800157658605, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 4, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.014839575091534218}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/mlbox/optimisation/optimiser.py:429: UserWarning: An error occurred while computing the cross validation mean score. Check the parameter values and your scoring function.\n",
      "  warnings.warn(\"An error occurred while computing the cross \"\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 0.9352493286132812 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.018395877571473748, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.8901058750346933, 'objective': 'binary', 'reg_lambda': 0.35701305062436184, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 9.975070101654946, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 4, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.01014972350016476}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 0.871588945388794 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.1151175597320497, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.6855610641414107, 'objective': 'binary', 'reg_lambda': 0.1569211464339545, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 9.426294542975482, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 4, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.011195914300192941}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 1.017467975616455 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.01885169797177598, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.8332183836018288, 'objective': 'binary', 'reg_lambda': 0.39284792370411736, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 7.071557211287477, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 4, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.023745426184953934}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 0.5785212516784668 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.01154826922770112, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.8980175715175995, 'objective': 'binary', 'reg_lambda': 1.0580623860513585, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 6.983296550763954, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 4, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.029539730019727775}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 0.4961879253387451 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.1189976904044587, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.6765514244791196, 'objective': 'binary', 'reg_lambda': 1.5511971997830027, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 6.949680020807191, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 4, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.03329223222634376}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 0.48798632621765137 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.036349940955998916, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.8380522422495096, 'objective': 'binary', 'reg_lambda': 1.4599262933571828, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 4.704092239701621, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 4, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.03541939392614133}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 0.49242353439331055 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.03243463144362711, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.8977344773989029, 'objective': 'binary', 'reg_lambda': 1.1732421285350587, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 4.940421388241644, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 4, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.037414431793644704}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 0.5088114738464355 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.12631716727910347, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.403232860841443, 'objective': 'binary', 'reg_lambda': 7.8922977397815135, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 4.76811074949344, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 4, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.021060122746670525}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 0.5377988815307617 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.17948645851284487, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.7199740028558584, 'objective': 'binary', 'reg_lambda': 2.232235123733561, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 2.766252548611436, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 7, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.018328234519326407}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.807803283915\n",
      "VARIANCE : 0.00652245168528 (fold 1 = 0.814634146341, fold 2 = 0.809756097561, fold 3 = 0.799019607843)\n",
      "CPU time: 0.7882161140441895 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.18242524348094227, 'strategy': 'l1'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1250, 'subsample': 0.7954178390782518, 'objective': 'binary', 'reg_lambda': 5.366271906704962, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 2.4743620885084026, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 7, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.040709722457326375}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/jose.lopez/workspace/python_virtualenvs/development/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.79802327435\n",
      "VARIANCE : 0.00969411496605 (fold 1 = 0.80487804878, fold 2 = 0.80487804878, fold 3 = 0.78431372549)\n",
      "CPU time: 0.6610441207885742 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.08418402028917599, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.41150590942940024, 'objective': 'binary', 'reg_lambda': 8.20473717035336, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 4.647037909640672, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.08293106577554732}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 1.393979787826538 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.0825766368335647, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.7613580215081427, 'objective': 'binary', 'reg_lambda': 8.298071637530306, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 5.361189532726847, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.08182975711903301}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 1.3886940479278564 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.0889377393153739, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.7963515860417667, 'objective': 'binary', 'reg_lambda': 8.799571574913653, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 4.387458107795608, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.08330298750143544}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.811079228439\n",
      "VARIANCE : 0.00187118963298 (fold 1 = 0.809756097561, fold 2 = 0.809756097561, fold 3 = 0.813725490196)\n",
      "CPU time: 1.4715864658355713 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.07669146953780642, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.7935660757635756, 'objective': 'binary', 'reg_lambda': 9.136767537737303, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 4.072555490090604, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.0630549664456996}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.811079228439\n",
      "VARIANCE : 0.00187118963298 (fold 1 = 0.809756097561, fold 2 = 0.809756097561, fold 3 = 0.813725490196)\n",
      "CPU time: 1.5538825988769531 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.07220996347400739, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.7946592691092582, 'objective': 'binary', 'reg_lambda': 8.825573495468769, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 1.3451105597171882, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.06308979347169119}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.72796110314\n",
      "VARIANCE : 0.0288008634982 (fold 1 = 0.765853658537, fold 2 = 0.721951219512, fold 3 = 0.696078431373)\n",
      "CPU time: 1.939516544342041 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.10268845689842748, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.8609720608744742, 'objective': 'binary', 'reg_lambda': 7.289974729872073, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 0.29993249773502484, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.07119999282557955}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.770317232584\n",
      "VARIANCE : 0.0204242794246 (fold 1 = 0.79512195122, fold 2 = 0.770731707317, fold 3 = 0.745098039216)\n",
      "CPU time: 1.9561560153961182 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.13551445847876606, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.7056180228741551, 'objective': 'binary', 'reg_lambda': 9.992990796161605, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 4.025926382383633, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.05978180192197199}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.809453212179\n",
      "VARIANCE : 0.00361829698122 (fold 1 = 0.809756097561, fold 2 = 0.80487804878, fold 3 = 0.813725490196)\n",
      "CPU time: 1.4174063205718994 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.10524164952416648, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.6452165730101025, 'objective': 'binary', 'reg_lambda': 9.061325728303183, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 3.0135112464165044, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 6, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.07123211574580715}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.809445241511\n",
      "VARIANCE : 0.000439616841484 (fold 1 = 0.809756097561, fold 2 = 0.809756097561, fold 3 = 0.808823529412)\n",
      "CPU time: 1.5268900394439697 seconds\n",
      "\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': nan}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}\n",
      "\n",
      ">>> FEATURE SELECTOR :{'threshold': 0.06732657481699088, 'strategy': 'rf_feature_importance'}\n",
      "\n",
      ">>> ESTIMATOR :{'silent': True, 'min_child_samples': 10, 'boosting_type': 'gbdt', 'n_estimators': 1000, 'subsample': 0.7460310663503162, 'objective': 'binary', 'reg_lambda': 6.174756007931965, 'subsample_for_bin': 50000, 'seed': 0, 'reg_alpha': 2.1547586644143952, 'nthread': -1, 'min_child_weight': 5, 'max_bin': 255, 'num_leaves': 31, 'min_split_gain': 0, 'max_depth': 3, 'colsample_bytree': 0.8, 'subsample_freq': 1, 'strategy': 'LightGBM', 'learning_rate': 0.054777358709384355}\n",
      "\n",
      "\n",
      "MEAN SCORE : accuracy = 0.724693129284\n",
      "VARIANCE : 0.0305339799886 (fold 1 = 0.760975609756, fold 2 = 0.726829268293, fold 3 = 0.686274509804)\n",
      "CPU time: 1.8907825946807861 seconds\n",
      "\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "{'ne__numerical_strategy': 'mean', 'ce__strategy': 'random_projection', 'est__reg_alpha': 4.387458107795608, 'fs__strategy': 'rf_feature_importance', 'fs__threshold': 0.0889377393153739, 'est__n_estimators': 1000, 'est__learning_rate': 0.08330298750143544, 'est__subsample': 0.7963515860417667, 'est__max_depth': 6, 'est__reg_lambda': 8.799571574913653, 'est__strategy': 'LightGBM', 'ne__categorical_strategy': nan}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'ne__numerical_strategy':{\n",
    "        \"search\": \"choice\",\n",
    "        \"space\": ['mean','median', 0]\n",
    "    },\n",
    "    'ne__categorical_strategy':{\n",
    "        \"search\": \"choice\",\n",
    "        \"space\": [np.NaN, None]\n",
    "    },\n",
    "    'ce__strategy':{\n",
    "        \"search\": \"choice\",\n",
    "        \"space\": ['label_encoding','entity_embedding','random_projection', 'dummification']\n",
    "    },\n",
    "    'fs__strategy':{\n",
    "        \"search\": \"choice\",\n",
    "        \"space\": ['l1','variance','rf_feature_importance']\n",
    "    },\n",
    "    'fs__threshold':{\n",
    "        \"search\":\"uniform\",\n",
    "        \"space\":[0.01, 0.3]\n",
    "    },\n",
    "    'est__strategy' : {\n",
    "        \"search\": \"choice\",\n",
    "        \"space\" : [\"XGBoost\", \"LightGBM\"]\n",
    "    },    \n",
    "    'est__max_depth': {\n",
    "        \"search\": \"choice\",\n",
    "        \"space\": [3, 4, 5, 6, 7]\n",
    "    },\n",
    "    'est__learning_rate': {\n",
    "        \"search\": \"uniform\",\n",
    "        \"space\": [0.01, 0.1]\n",
    "    },\n",
    "    'est__subsample': {\n",
    "        \"search\": \"uniform\",\n",
    "        \"space\": [0.4, 0.9]\n",
    "    },\n",
    "    'est__reg_alpha': {\n",
    "        \"search\":\"uniform\",\n",
    "        \"space\": [0, 10]\n",
    "    },\n",
    "    'est__reg_lambda': {\n",
    "        \"search\":\"uniform\",\n",
    "        \"space\": [0, 10]\n",
    "    },\n",
    "    'est__n_estimators': {\n",
    "        \"search\": \"choice\",\n",
    "        \"space\": [500, 1000, 1250, 1500]\n",
    "    }\n",
    "}\n",
    "\n",
    "best = opt.optimise(space, data, max_evals=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... finally to predict on the test set with the best parameters (or None for default configuration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fitting the pipeline...\n",
      "CPU time: 0.5700221061706543 seconds\n",
      "\n",
      "dumping feature importances into directory : save\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABOUAAAEJCAYAAADb4ZPZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xdc19X////bC14gAiIqouFWNBTciqvEAfYOR73LTM29\nc5SpqA0zS76uHJWrnO9MTXxrbzXFAje4UHPhXuEAiTBHCgg8f3/48/WJGDkQFO7Xy4VLvM7znPN8\nnCenywUfnPM8JsMwDERERERERERERCTHWOV2ACIiIiIiIiIiIvmNknIiIiIiIiIiIiI5TEk5ERER\nERERERGRHKaknIiIiIiIiIiISA5TUk5ERERERERERCSHKSknIiIiIiIiIiKSw5SUExEREXkGLF26\nlAoVKmBtbc2AAQNyO5xsN3r0aLy8vHI7jDxr2bJl1K9f/7H78fHxYd68edkQkYiIiCgpJyIiInmC\nyWTK8qt8+fJP9P4XL16kc+fOVK1aFWtra9q0aZNhvUuXLvHaa69RqFAhnJ2d6dKlC7///nuWfSck\nJNCnTx+6d+/OxYsXmTx5crbF/cILLzwVSb6PPvqIbdu25XYYWUpOTsZkMvH999/ndigPJTExkVGj\nRvHpp59ayvbv30/t2rVxdHTEz8+Py5cvp2kzePBg3nvvvXR9ffbZZ3z00Ufcvn37icctIiKS1ykp\nJyIiInlCdHS05WvVqlUAHDhwwFIWERHxRO9/584dXFxcGDlyJD4+PhnWSU5O5uWXXyYmJobNmzez\nYcMGDh06RPv27bPs+9KlSyQkJNC6dWvc3NxwcnJ6EkN4bElJSY/c1tHRkWLFimVjNNnrccaW24KC\ngrC2tuZf//qXpax79+74+flx8OBB7OzsGD16tOXajh07+PnnnwkMDEzXV9OmTXF2dmbZsmU5EruI\niEhepqSciIiI5AklS5a0fBUtWhSA4sWLW8qKFy8OwB9//EHv3r1xcXHBzs6OBg0asGXLFks/J06c\nsKyGatasGXZ2dri7u7N69eos71+lShW+/PJLevbsiaura4Z1NmzYQGRkpGUrYePGjVm8eDFbt25l\n9+7dGbaZO3culStXBsDb2xuTyWSpu2fPHlq2bImDgwMlSpSgQ4cOXLp0ydL29OnTvPrqq5QsWRJ7\ne3tq1qzJihUrLNc7duxIeHg4X3/9tWVF4e7duy3PYN++fWliKV26NBMnTgTurd4zmUzMmTOHDh06\nUKhQIfr27QvAlStX6NKlCy4uLjg5OfHiiy+yc+fOLJ/f37ev3v+8dOlSKlasiIODA2+88QZ//vkn\n33//PZUrV8bJyYmOHTty69atNGNq06YNkyZN4rnnnsPBwYFOnTpx/fp1Sx3DMJgwYQLly5fH1tYW\nd3d3Zs2alSaekiVLMm7cOPr160fRokXx8/OjdOnSAHTq1AmTyYSdnR0Av/32G506daJMmTIULFgQ\nDw8PvvrqqzT93Y9r1qxZlC1blsKFC/Paa68RFxeXpl5wcDCNGzfG3t4eZ2dnmjdvTlRUlOX6kiVL\nqFGjBnZ2dlSoUIGRI0dy586dLJ/t0qVLadeuHSaTyTL+EydOMHDgQNzd3enVqxfHjh0D7iWX+/Tp\nwzfffIO9vX2G/b366qt89913Wd5TRERE/pmSciIiIpKvdO3ala1bt/L9999z4MAB6tSpw8svv8y5\nc+fS1BsxYgRvv/02hw4d4rXXXqNDhw6WxMWjCg8Px8PDI81W2rp161K8eHHCwsIybNO9e3d27NgB\nwMaNG4mOjqZu3bocPHiQ5s2b06JFCw4cOMDPP/9MUlISL730Enfv3gXg5s2bvPTSS/z8888cOXKE\n7t2707lzZ0uC7Ouvv8bb25tu3bpZVhTWrVv3ocb08ccf06JFCw4ePMiYMWO4desWPj4+pKSk8PPP\nP7N//35atGhBy5YtOXv27EP1feHCBVauXMmaNWtYt24doaGhvPbaayxbtozVq1ezdu1aQkJCmDJl\nSpp227dvJyIigpCQENatW8fu3bvTbNGdNm0a48ePZ+zYsURGRjJ06FDee+89li5dmqafqVOnUr58\nefbs2cPXX3/NL7/8AtxLlEZHR/Prr78C9xJZderUYe3atRw7dozRo0czcuRIli9fnqa/sLAw9u7d\nS3BwMOvXryciIoL333/fcn3Dhg20adOGJk2asHv3bnbu3EmnTp0sP8+5c+fy3nvvMXr0aI4dO8bC\nhQv58ccfeeeddzJ9hikpKYSFheHt7W0pM5lM1KhRg+DgYFJSUti4cSM1a9YEYMyYMbRs2ZJmzZpl\n2meDBg3YtWsXCQkJmdYRERGRB2CIiIiI5DFbtmwxAOPixYtpyo8ePWoAxqZNmyxlqampRrVq1Yy3\n337bMAzDOH78uAEY48ePT9O2Tp06Rp8+fR7o/m+++abRunXrdOVdu3Y1mjdvnq7cy8vLGDZsWKb9\n3Y8pIiIizT26d++ept6tW7cMs9lsBAcHZ9pXq1atjMGDB1s+N2nSxOjfv/8/3s8wDKNUqVLGhAkT\nDMMwjDt37hiAMXDgwDR15syZY1SoUMFISUlJU96oUSNj1KhRmcY1atQow9PTM83nAgUKGNeuXbOU\n9erVy7CxsTHi4+MtZf369TOaNGli+fzmm28ahQsXNm7evGkpW7NmjWEymYyoqCjDMAzDxcXFGDNm\nTJr7DxgwwKhatarlc4kSJQx/f/80de7evWsAxvLlyzMdx1/jatOmTZq43NzcjKSkJEvZJ598YpQv\nX97yuV69esbrr7+eYX+pqalGyZIljUWLFqUp/+mnnwyTyWT8+eefGbaLjo42AGPz5s1pyo8cOWI0\nbdrUKFOmjPHaa68ZV69eNfbs2WNUqFDBiIuLMwYPHmxUrFjRaNmypXH27Nk0bffs2WMAxpkzZ/7x\nOYiIiEjmtFJORERE8o3IyEisrKx44YUXLGUmk4kXX3yRyMjINHUbNWqU5nPjxo3T1clNERERLF++\nHEdHR8tXiRIlSElJ4fTp0wDcunWLgIAAqlWrRpEiRXB0dGTz5s2WFV7Z4a8rsO7HFRUVhZOTU5rY\nIiIiLHE9qHLlyuHs7Gz5XLJkScqUKUORIkXSlMXGxqZpV6NGDRwdHS2fmzRpgmEYHD9+nNjYWOLi\n4mjatGmaNj4+Ppw+fdqyKi2jsWUmOTmZ8ePHU6NGDYoVK4ajoyOLFi1K95w9PT2xsbGxfHZzc+Pq\n1avAvS2lv/zyC61atcrwHpcuXSImJoaBAwemea7//ve/MQwj01WI97e23t9qe5+Xlxfbtm0jKiqK\nVatW4ezsTK9evZg7dy7/+c9/OHnyJMePH8ff35+ePXumaXu/r3/aNisiIiJZM+d2ACIiIiL5xXPP\nPZfuPW0AV69e5bnnnnuovlJTU+nTp0+GJ2S6uLgA8O6777Jp0yY+//xzKleujIODA4MHD/7HQwus\nrO793dYwjDTlf01Y3efg4JAurlq1amV4Qunf6/6Tvyaw4F4CNaOy1NTUh+r3QT1ovBMmTGD69OlM\nnz6dGjVqUKhQISZOnJhuS7KtrW2azw8T+/16c+fOpXHjxumulylTJsN299+lGB8fn2X/n376KQ0a\nNKBVq1bMmDGDN998E1tbW7p160ZAQACJiYkUKFAgTV/3+xYREZFHo6SciIiI5Buenp6kpqYSFhZG\nixYtgHuJpx07dqR7h9bu3bstdQB27txJ7dq1H+v+TZo0YcqUKURFRVG2bFng3gmxv/32W5rVew+i\nXr16HD58GHd390zrbN++ne7du1tOd01OTub06dOWgyPgXqIoJSUlTbv7B1VcuXLFUnb58uV0K9Iy\ni2v16tUULVrUcuBGTjty5Ah//vmnJam2c+dOTCYTVatWxdXVFRcXF7Zv346vr6+lzbZt26hSpUq6\npN9fWVtbY21tne55bd++nbZt29K9e3dL2alTpx4qZpPJRO3atfn555/p169fuutlypTB1dWVU6dO\n0a1btwfu19HRkcqVKxMZGUnr1q0zrHPw4EG+++47Dh06BNxLAN5PwCYlJWEYRprk4ZEjRyhTpgwl\nSpR4mCGKiIjI32j7qoiIiOQbnp6etG3bln79+hEaGsrx48cZOHAgZ8+eZfjw4Wnqzpkzh6CgIE6d\nOsXo0aM5ePAgQ4cOzbRvwzA4ePAgBw8e5I8//uDGjRscPHiQw4cPW+r4+/vj6elJ586d2bdvH7t2\n7aJnz574+PjQsGHDhxrLRx99xIEDB+jZsyf79u3j3LlzbNq0icGDB1tOYH3++edZvXo1+/fvJzIy\nkl69eqU77bNChQpERERw7tw54uLiSE5OxtnZmbp16zJx4kSOHDlCREQE3bt3T7cFMiPdu3enZMmS\ntGnThk2bNnHhwgV2797N+PHjWb9+/UON8VGlpKTQs2dPjh49ypYtW3j33Xd54403LKvJ3n//faZO\nncqiRYs4ffo0M2fOZMGCBXzwwQdZ9msymShXrhybN28mOjqa33//Hbj3nENDQ9mxYwcnT55k5MiR\nlgTXw/j4449ZvXo1AQEBHDlyhBMnTrBgwQLOnj2LlZUV48eP5/PPP2fSpElERkZy4sQJVq9ezaBB\ng7Ls19/fn23btmV4LTk5mV69ejFz5kwKFy4MQNOmTZk3bx7Hjx9n0qRJeHt7U7BgQUubrVu34u/v\n/9DjExERkbSUlBMREZF85dtvv8XHx4eOHTtSq1YtDhw4QHBwMBUrVkxTb/LkyXz11VfUqFGDlStX\n8v333+Pl5ZVpv4mJidSuXZvatWvz008/sWPHDmrXrp3mvWRms5ng4GCKFy9Os2bN+Ne//oWXlxer\nVq166HHUrFmTsLAwfvvtN3x9ffH09GTAgAEkJyfj5OQEwFdffYWrqytNmzbFz8+PKlWq0LZt2zT9\njBo1Cnt7e6pXr07x4sUt22u//fZbrK2tadCgAV26dGHo0KEUK1bsH+NydHQkLCwMT09PunTpQpUq\nVWjfvj0HDx60rA580po2bUqtWrVo2bIlrVu3pn79+nz99deW6++99x4ffvgh48aNw9PTkxkzZjB9\n+nTeeuutf+x7xowZhIWFUa5cOUqVKgXAuHHjaNCgAf7+/jRp0oSkpKQ0p70+qLZt27J27Vq2bdtG\n/fr1adiwIcuWLbOs3uvbty/fffcdq1evpl69enh7ezN+/HhKly6dZb8DBgwgJCTE8v66v5o4cSLV\nqlWjTZs2lrKhQ4fy/PPP06BBA8LDw1m4cKHl2h9//MH69evp37//Q49PRERE0jIZf39ZiIiIiEg+\nduLECapWrUpERAT16tXL7XDkIXXs2JFbt27x448/5nYoT5W33nqLMmXKMHHixMfq59NPP+WXX37h\nhx9+yKbIRERE8i+tlBMRERERyeOmTJmSLe/4K1SoENOnT8+GiEREREQHPYiIiIiI5HFubm6MHDny\nsfvJ6LRfEREReTTavioiIiIiIiIiIpLDtH1VREREREREREQkhykpJyIiIiIiIiIiksP0Trk87MqV\nK7kdgsgT5eLiQlxcXG6HIfLEaa5LfqB5LvmB5rnkB5rnkte5ubllW19aKSciIiIiIiIiIpLDlJQT\nERERERERERHJYUrKiYiIiIiIiIiI5DAl5URERERERERERHKYknIiIiIiIiIiIiI5TEk5ERERERER\nERGRHKaknIiIiIiIiIiISA5TUk5ERERERERERCSHmQzDMHI7CHkyLraul9shiIiIiIiIiEg+ZT1v\nbW6HkO3c3NyyrS+tlBMREREREREREclhSsqJiIiIiIiIiIjkMCXlREREREREREREcpiSciIiIiIi\nIiIikm9cvnyZ9u3b06xZM5o3b878+fMBOHr0KG3atMHPz4+XX36ZX375JcP21tbW1KpVi1q1atGu\nXTtLee/evalZsyY1atSgffv23Lp1K8s4ci0pt3fvXjp06MDly5cfuY9Zs2axe/duAObOnculS5ey\nKzwAVq9eneZz165ds7V/ERERERERERHJWWazmbFjx7J161bWrVvH4sWLOXXqFIGBgQwbNoyQkBBG\njBhBYGBghu0LFizIwYMHOXjwIGvX/t9hFtOnT+fQoUMcPnyYsmXLMnPmzCzjyLWkXHh4OB4eHoSH\nh2dLfwMGDKB06dLZ0td9P/zwQ7b2JyIiIiIiIiIiuatEiRJUr14dAEdHRypXrkxMTAwmk4mbN28C\ncPPmTUqUKPFQ/To5OQFgGAZ37tzBZDJlWd/8CLE/toSEBE6cOMHYsWOZNGkSHTp0IDIykqCgIOzs\n7IiJicHT05M+ffpgZWVF165dadmyJYcPH8bZ2ZmhQ4daBnrfJ598QteuXalUqRIHDx5k+fLlpKam\nUqhQIT7++GPOnDnDokWLuHv3Lra2tgwcOBA3Nze2bt3Kvn37SExM5OrVq3h7e9OlSxeWLl1KUlIS\nAQEBlClThnfeecdyr8jISFauXEmhQoW4ePEiFStWZMiQIZhMJs6cOcPixYtJTEzEbDbz8ccfY21t\nzfz58zl79izW1tZ069YNLy8vtm7dyt69e0lMTCQmJoa2bduSnJzM9u3bsbGx4f3338fR0ZGYmBgW\nLFjAjRs3KFCgAP3796dUqVI5/WMTEREREREREclTLl68yNGjR6lduzbjxo2jc+fOfPbZZxiGwZo1\nazJsk5CQQL169TCbzYwePZpXX33Vcq1nz55s2LCBatWqMXXq1CzvnStJuYiICGrVqoWbmxuFChXi\n3LlzAJw5c4Zp06ZRvHhxAgMD2bt3Lw0bNiQxMZFKlSrRo0cP/vvf/7Jy5Up69+6dYd83btzg66+/\nZty4cbi6ulr277q5ufHpp59ibW3N4cOHWbZsGSNGjADgwoULTJ48GbPZzNChQ/nXv/7FW2+9xcaN\nG5kyZUqG9zl//jzTpk2jSJEijBkzhpMnT+Lu7s6MGTMYOnQo7u7u3L59G1tbWzZs2ADA1KlTuXz5\nMuPHj+eLL74A7v3wJ0+ezN27dxkyZAhvvfUWkydPZvHixWzbto3WrVvzzTff0LdvX5577jlOnz7N\n/PnzGTt2bLqYQkNDCQ0NBWDixImP8RMSEREREREREXk8Li4uuR1Clm7dusXbb7/N9OnTqVChAl9+\n+SXTpk3j3//+N//9738ZPXo0GzduTNfu119/pVSpUpw7d44WLVpQvXp1KlWqBMCiRYtISUlhyJAh\nrFixgp49e2Z6/1xJyoWHh+Pv7w9A48aNCQsLo27duri7u1uWBjZp0oQTJ07QsGFDTCYTjRs3BuDF\nF1/k888/z7TvU6dOUbVqVVxdXYF7yxABbt++zaxZs4iJiQEgJSXF0sbLywt7e3sASpcuTVxc3D9O\nHHd3d4oVKwZA+fLliY2Nxd7eniJFiuDu7g5g6fPEiRO8/PLLAJQqVYrixYsTHR0NgKenJwULFqRg\nwYLY29tTr149AMqWLUtUVBQJCQmcPHmSadOmWe6dnJycYUy+vr74+vpmGbeIiIiIiIiISE6Ii4vL\n7RAydffuXbp3707btm154YUXiIuLY8mSJXzwwQfExcXh4+ND//79043Bzc3NsnuxYsWKNGvWjF9+\n+cWSlIN7B0F07NiRyZMnP11JuVu3bnH06FGioqIwmUykpqYCUKdOnQfu45/25GZkxYoVeHp6EhAQ\nQGxsLOPGjbNcs7GxsXxvZWWVJmGXmb+3uT+Oh/X3fsxmc5o4UlNTcXBwyHTFnoiIiIiIiIiIPDjD\nMBg+fDju7u7079/fUl6iRAl27dplWUBWoUKFdG2vXbuGvb09BQoUIC4ujvDwcEaOHIlhGJw9exZ3\nd3cMw2Dt2rV4eHhkGUeOH/Swe/dumjZtyuzZs5k1axZz5szB1dWVEydOcObMGWJjY0lNTWXXrl2W\n4A3DsJyyGhYWluWgqlSpwvHjx4mNjQWwbF+9ffs2RYsWBWDr1q0PFKvZbM50VVpG3NzcuHbtGmfO\nnAHgzp07pKSkULVqVXbs2AHAlStXiIuLw83N7YH6tLe3x9XVlV27dgH3nsWFCxceOCYRERERERER\nEfk/ERERrFq1ip07d+Ln54efnx+bNm1iypQpfPrpp/j6+jJp0iQmT54MwKFDhyyvQDt+/Dj16tWj\nZs2aNG/enNGjR1OtWjUMw6B79+5Ur16d6tWrEx0dzccff5xlHDm+Ui48PJxXXnklTVmDBg0ICQnB\n3d2dBQsWWA568Pb2BqBAgQKcOXOG1atX4+TkxHvvvZdp/05OTvTr14/PP/8cwzBwcnJizJgxvPLK\nK8yaNYvVq1c/8Kq8li1bEhAQQIUKFdIc9JCZ+++kW7RoEUlJSdja2jJmzBhatWrF/PnzGT58ONbW\n1gwcODDNCrl/8s477zBv3jxWr15NcnIyTZo0oXz58g/cXkRERERERERE7vH29uby5csZXsvoHXI1\na9akZs2awL3XsB05ciRdHSsrK8LDwx8qDpNhGMZDtXhCIiMjWbduHaNHj053rWvXrixZsiQXonq2\nXWxdL7dDEBEREREREZF8ynre2twOIds96M7HB5Hj21dFRERERERERETyu6dmpZxkP62UExERERER\nEZHcopVyWVNSLg+7cuVKbocg8kS5uLg81Udsi2QXzXXJDzTPJT/QPJf8QPNc8jptXxURERERERER\nEXmGKSknIiIiIiIiIiKSw5SUExERERERERERyWHm3A5AnpyUvu1yOwSRJ+pqbgcgkkM01yU/0DyX\n/EDzXPKKvPjyfpHcoJVyIiIiIiIiIiIiOUxJORERERERERERkRympJyIiIiIiIiIiEgOU1JORERE\nRERERJ55ly9fpn379jRr1ozmzZszf/78NNfnzp1LqVKliI+Pz7D9+PHjad68OT4+PowZMwbDMHIi\nbMnH8kRSrmvXrk/8Hnv37qVDhw5cvnz5id8rK+vXrycxMTFXYxARERERERF52pjNZsaOHcvWrVtZ\nt24dixcv5tSpU8C9hN327dspVapUhm0jIiKIiIggNDSUzZs3c/DgQXbt2pWT4Us+lCeScjkhPDwc\nDw8PwsPDczWODRs2KCknIiIiIiIi8jclSpSgevXqADg6OlK5cmViYmIA+OSTT/jwww8xmUwZtjWZ\nTCQmJpKUlERSUhLJyckUL148x2KX/Mmc2wE8KbGxscyZM4ebN2/i5OTEwIEDcXFxYd++faxevZrk\n5GQKFSrEkCFDcHZ2JigoiLi4OGJjY4mLi8Pf3x9/f38AEhISOHHiBGPHjmXSpEl06NABgMjISIKC\ngnBwcCAqKopGjRpRtmxZNmzYQFJSEgEBAZQsWTLTWGbNmkXdunVp2LAhcG/F35IlS4iMjGTlypUU\nKlSIixcvUrFiRYYMGUJwcDDx8fGMGzcOJycnxo4dm2vPV0RERERERORpdfHiRY4ePUrt2rX56aef\neO655/D09My0fr169WjcuDF16tTBMAx69OhB5cqVczBiyY/ybFJu4cKF+Pj40KxZMzZv3szChQsZ\nOXIkHh4eBAYGYjKZ2LRpE2vXrqVbt24AXLlyhbFjx3Lnzh2GDh1Kq1atMJvNREREUKtWLdzc3ChU\nqBDnzp2jYsWKAPz6669Mnz4dR0dHBg8eTMuWLZkwYQIbNmxg48aN9OjRI9NYsnL+/HmmTZtGkSJF\nGDNmDCdPnsTf35/169czduxYnJyc0rUJDQ0lNDQUgIkTJ2bzExUREREREREBFxeXTK+ZzeYsr+eE\nW7du8fbbbzN9+nRKlCjBnDlzWL9+PYULF8ba2pqiRYumi/HMmTP8+uuvnD9/HgB/f39OnDjBCy+8\nkBtDkHwizyblTp8+zYgRIwBo2rQpS5cuBSA+Pp4ZM2Zw7do1kpOTcXV1tbSpU6cONjY22NjYULhw\nYa5fv06xYsUIDw+3rJpr3LgxYWFhlqRcpUqVKFKkCAAlS5akRo0aAJQtW5ajR49mGUtW3N3dKVas\nGADly5cnNjYWDw+PLNv4+vri6+v7YA9IRERERERE5BHExcVles3FxSXL60/a3bt36d69O23btuWF\nF15g//79nDt3jjp16gAQHR1N/fr1Wb9+fZp8wPLly/Hy8iIhIQGAF198kc2bN//jv8Ml/3Fzc8u2\nvvJsUi4zCxcupE2bNtSrV8+yTfQ+s/n/HoeVlRUpKSncunWLo0ePEhUVhclkIjU1Ffi/wyVsbGws\nbUwmk+XzX+tmxtra2lInNTWV5ORky7W/9mtlZfWPfYmIiIiIiIjkZ4ZhMHz4cNzd3enfvz8AVatW\n5fDhw5Y6DRo0IDg4mKJFi6Zp6+bmxrJly0hOTsYwDHbt2kWfPn1yNH7Jf/LsQQ9VqlRh586dAISF\nhVmy27dv37b8z7dt27Z/7Gf37t00bdqU2bNnM2vWLObMmYOrqyvHjx9/7FiKFy/OuXPnANi3bx8p\nKSn/2JednZ0lcy8iIiIiIiIi90RERLBq1Sp27tyJn58ffn5+bNq0KdP6hw4dsuxqa9OmDeXKlaNl\ny5b4+flRrVo1WrVqlVOhSz6VJ1bKJSUlMWDAAMvnNm3a0KtXL2bPns3atWsthysAvPHGG0ybNg0H\nBwe8vLyIjY3Nsu/w8HBeeeWVNGUNGjQgPDycxo0bP1B8mcXSsmVLpkyZQkBAADVr1qRAgQL/2Jev\nry+BgYEULVpUBz2IiIiIiIiI/P+8vb25fPlylnX27Nlj+b5mzZrUrFkTuLeTbfLkyU80PpG/MxmG\nYeR2EPJkXGxdL7dDEBERERERkTzGet7aTK/l9jvlRJ607HynXJ7dvioiIiIiIiIiIvK0UlJORERE\nREREREQkhykpJyIiIiIiIiIiksPyxEEPkrGs9vmL5AV6X4XkF5rrkh9onkt+oHkuIiJ/pZVyIiIi\nIiIiIiIiOUxJORERERERERERkRympJyIiIiIiIiIiEgO0zvl8rCUvu1yOwSRJ+pqbgcgkkM01yU/\neBbnud7fKyIiIo9DK+VERERERERERERymJJyIiIiIiIiIiIiOUxJORERERGRPGTYsGHUqFGDFi1a\npClfuHAhTZs2pXnz5owfPz5du8uXL9O+fXuaNWtG8+bNmT9/vuXaunXraN68OaVLl+bQoUNPfAwi\nIiL5QbZGpHx7AAAgAElEQVQk5f744w9mzJjBkCFDGDVqFBMmTODKlSvZ0XWWgoKCWLv23rs8VqxY\nweHDh7O1//Xr15OYmGj5PGjQIG7cuJGt9xARERERyU4dOnRg6dKlacrCw8P56aefCAkJYcuWLQwY\nMCBdO7PZzNixY9m6dSvr1q1j8eLFnDp1CgAPDw/mzZtHw4YNc2QMIiIi+cFjH/RgGAZTpkzBx8eH\noUOHAnDhwgWuX7+Om5vbYwf4oN58881s73PDhg28+OKLFChQINv7FhERERF5Eho2bMjFixfTlH37\n7bcMGjTI8nuti4tLunYlSpSgRIkSADg6OlK5cmViYmKoUqUKlStXfvKBi4iI5DOPnZSLjIzEbDbT\nqlUrS1n58uUxDIMlS5Zw8OBBAF5//XUaN25MQkICkydP5s8//yQ5OZmOHTtSv359YmNj+X//7/9R\nsWJFzp8/T+nSpRk8eDAFChRg0KBBNGrUiF9++QVbW1veffddSpYsmSaOWbNmUbduXRo2bMiZM2dY\nvHgxiYmJmM1mPv74Y27evMnMmTMtK9969erF888/T2RkJCtXrqRQoUJcvHiRihUrMmTIEIKDg4mP\nj2fcuHE4OTkxduxYy71iY2OZMGECzz//PKdOnaJo0aKMHDkSW1tbYmJimDdvHjdu3MDKyor33nuP\nEiVK8N1336V7FpGRkQQFBeHg4EBUVBSNGjWibNmybNiwgaSkJAICAihZsiQ3btzgm2++4ffffweg\ne/fueHh4PO6PTkRERETyiXPnzrF3714mT55MgQIFGDNmDLVq1cq0/sWLFzl69Ci1a9fOwShFRETy\nl8dOykVFRVGhQoV05Xv27OHChQtMmTKFGzdu8P7771O1alWcnJwYMWIE9vb23Lhxgw8//JB69eoB\ncOXKFQYMGICHhwezZ8/mp59+ol27dgDY29szdepUtm3bxuLFixk9enSG8SQnJzNjxgyGDh2Ku7s7\nt2/fxtbWlsKFC/PRRx9ha2tLdHQ0X3zxBRMnTgTg/PnzTJs2jSJFijBmzBhOnjyJv78/69evZ+zY\nsTg5OaW7T3R0NO+++y4DBgxg2rRp7N69m6ZNm/Lll1/y6quv4u3tTVJSEoZhZPosAH799VemT5+O\no6MjgwcPpmXLlkyYMIENGzawceNGevTowaJFi2jTpg0eHh7ExcURGBjI9OnTH/dHJyIiIiL5REpK\nCn/88Qfr1q3j4MGDDBgwgF27dmEymdLV/fPPP+nbty/jxo2jUKFCuRCtiIhI/vDYSbnMnDhxgiZN\nmmBlZYWzszPVqlXj7Nmz1KpVi+XLl3P8+HFMJhPx8fFcv34dgGLFillWgDVt2pQNGzZYknJNmjSx\n/Pc///lPpve9cuUKRYoUwd3dHbiXzANITExkwYIFXLhwASsrK6Kjoy1t3N3dKVasGHBvlV9sbOw/\nrkRzdXWlfPnyAFSsWJHffvuNO3fuEB8fj7e3NwC2trZZPouCBQtSqVIlihQpAkDJkiWpUaMGAGXL\nluXo0aMAHDlyhEuXLlnuffv2bRISErCzs0sTU2hoKKGhoQCWhKOIiIiIPBkZbQF9Wty6dQtra2tL\njGXLlqVjx44UL14cPz8/zOZ7/wz4+xju3r1L9+7d6dKlC926dUvXr42NDc7Ozk/12J9mZrNZz07y\nPM1zkQf32Em5MmXKsGfPngeuHxYWxo0bN5g4cSJms5lBgwaRlJQEkO4vdX/9nNn3D+rHH3+kcOHC\nTJkyBcMweOuttyzXbGxsLN9bWVmRmpr6j/39vc39MTysv/ZjMpksn00mkyUOwzAIDAy0JPky4+vr\ni6+v7yPFISIiIiIPJy4uLrdDyNS1a9dISUmxxNiiRQuCg4Px8vLi7NmzJCQkAGnHYBgG7777LuXK\nlaNLly4Zju/u3bv88ccfT/XYn2YuLi56dpLnaZ5LXped5yc89umrXl5e3L1717JCC+5tyXRwcGDX\nrl2kpqZy48YNjh8/btlOWrhwYcxmM0ePHuW3336ztIuLi7Oc8BQWFpZmtdrOnTst/83qRbNubm5c\nu3aNM2fOAHDnzh1SUlK4ffs2RYoUwcrKiu3btz9Q4s3Ozs7yC8uDKFiwIMWKFWPv3r3AvV9aEhMT\nqVq1aobP4kHVqFGDjRs3Wj5fuHDhgduKiIiISP4ycOBA2rVrx9mzZ6lbty7Lly+nY8eOREVF0aJF\nCwYOHMiMGTMwmUzExMTQtWtXACIiIli1ahU7d+7Ez88PPz8/Nm3aBEBwcDB169Zl//79dOvWjc6d\nO+fmEEVERPKEx14pZzKZGDFiBIsXL2bNmjXY2NhQvHhxevToQUJCAgEBAQB06dIFZ2dnXnjhBSZN\nmsTw4cOpVKkSpUqVsvTl5ubGxo0bmTNnDqVKlUpzeMStW7cYMWIENjY2vPvuu5kPyGxm6NChLFq0\niKSkJGxtbRkzZgwvvfQSU6dOZfv27dSsWfOBTlT19fUlMDCQokWLpjnoISuDBw/mm2++ISgoCGtr\na4YNG4a3tzenTp1K9ywuX778QH327NmTBQsWMGLECFJSUqhatSr9+vV7oLYiIiIikr/Mnj07w/Kv\nvvoqXVnJkiVZsmQJAN7e3pn+fvryyy/z8ssvZ1+QIiIigskwDCO3g4B7J5pOmjSJqVOnprs2aNAg\nJkyYkOGBC5K5i63r5XYIIiIiInmW9by1uR2CPGO0rU/yA81zyeuequ2rIiIiIiIiIiIi8nCempVy\nkv20Uk5ERETkydFKOXlYWkEk+YHmueR1WiknIiIiIiIiIiLyDHvsgx7k6aW/3kpep7/CSX6huS75\ngea5iIiI5DdaKSciIiIiIiIiIpLDlJQTERERERERERHJYUrKiYiIiIiIiIiI5DC9Uy4PS+nbLrdD\nEHmiruZ2ACI5RHP92aR3u4qIiIhIVrRSTkREREREREREJIcpKSciIiIiIiIiIpLDlJQTERERERER\nERHJYXqnnIiIiEg+M2zYMEJDQ3FxcWHz5s0AfPbZZ4SEhGBra0u5cuWYNm0ahQsXTtd2/vz5LFu2\nDMMw6Ny5M3379gVgwIABnD17FoAbN27g5ORESEhIzg1KRERE5BmjlXIiIiIi+UyHDh1YunRpmrKm\nTZuyefNmQkNDqVixIjNnzkzX7sSJEyxbtoz169cTEhJCaGgo58+fB2Du3LmEhIQQEhKCv78//v7+\nOTIWERERkWfVM5OU++OPP5gxYwZDhgxh1KhRTJgwgStXrjxSX1u3bmXBggUA/Pzzz2zbts1SHh8f\nn2XbTz75xPJXYIDY2FiGDx8OwNmzZ1m4cGGmbWNjYwkLC3ukmEVERESyS8OGDXF2dk5T5uPjg9l8\nbxNFnTp1iI6OTtfu9OnT1K5dm4IFC2I2m2nYsCHBwcFp6hiGwbp163jllVee3ABERERE8oBnYvuq\nYRhMmTIFHx8fhg4dCsCFCxe4fv06bm5uAKSkpGBtbf3Qfbdq1cry/datWylTpgxFixZ9pDgrVapE\npUqVMr3+22+/ERYWxgsvvPDAfT7quEREREQe1ffff0+7du3SlXt4eDBp0iTi4+MpWLAgmzdvpmbN\nmmnq7Nmzh+LFi1OxYsWcCldERETkmfRMJOUiIyMxm81pEmjly5cnMjKSjz/+GAcHB65cucIXX3zB\n9u3bCQ4OJjk5mcqVK9OnTx+srKzYsmUL//vf/7C3t6dcuXLY2NgAEBQUhJ2dHa6urpw9e5Yvv/wS\nW1tbAgMDsbW1feg4161bx+jRozl27BiLFi0CwGQyMW7cOJYtW8alS5cICAjAx8eHVq1aMX/+fM6e\nPYu1tTXdunXDy8uLrVu3smfPHhISEkhNTaV48eJ4e3vj7e0NwJdffkmjRo2oX79+mvuHhoYSGhoK\nwMSJEx/5eYuIiMjjc3Fxye0QsnTr1i2sra3TxTlx4kTs7e3p168fJpMpzTUXFxdGjRpFt27dcHBw\noG7duhQoUCBNHxs3bqRz584PPX6z2fzUPzORx6V5LvmB5rnIg3smknJRUVFUqFAhw2vnz59n6tSp\nuLq6cunSJXbu3Mlnn32G2Wxm/vz57Nixgxo1ahAUFMSkSZOwt7dn3LhxlC9fPk0/DRs2ZOPGjXTt\n2jXL1W6AJXEHkJycjJVV+l3Aa9eupXfv3nh4eJCQkICNjQ2dO3e2JO0A1q1bB8DUqVO5fPky48eP\n54svvrCM6/PPP8fR0ZFjx47x448/4u3tze3btzl58iSDBg1Kd09fX198fX2zfpgiIiKSI+Li4nI7\nhCxdu3aNlJSUNHGuWLGCNWvWEBQUxO+//55hu7Zt29K2bVsAJkyYwHPPPWfpIzk5mR9++IHg4OCH\nHr+Li8tT/8xEHpfmueQHmueS193fsZkdnomkXFbc3d1xdXUF4OjRo5w/f573338fgKSkJJycnDh9\n+jSenp44OTkB0KhRowzfk/Kg3nnnHUviLjY2lkmTJqWr4+HhwbfffssLL7xAgwYNKFasWLo6J06c\n4OWXXwagVKlSFC9e3BJXjRo1cHR0BKBatWrMnz+fGzdusHv3bho0aKAtrSIiIpKttmzZwpw5c1i1\nahUFCxbMtF5cXBwuLi5cvnyZ4OBgyx8ZAXbs2IG7u3u2/rIqIiIiklc9E0m5MmXKsGfPngyvFShQ\nwPK9YRj4+PjQuXPnNHX27t37ROPLyKuvvkqdOnU4cOAAY8aM4cMPP3yo9n8dF9w7EW379u3s3LmT\ngQMHZmeoIiIiks8MHDiQXbt2ER8fT926dRkxYgQzZ84kMTGRjh07AvcOe5g0aRIxMTEEBASwZMkS\nAPr27cu1a9cwm80EBgZSuHBhS79r1qzRAQ8iIiIiD+iZSMp5eXmxfPlyQkNDLdszf/31V44fP56m\nXvXq1Zk8eTKtW7emcOHC3Lp1izt37lC5cmUWL17MzZs3KViwILt376ZcuXLp7mNnZ8edO3eyJeaY\nmBjKli1L2bJlOXv2LJcvX8bFxSVN/1WrVmXHjh14eXlx5coV4uLicHNz4/z58+n6a9asGR988AHO\nzs6ULl06W2IUERGR/Gn27Nnpyjp16pRh3ZIlS1oScgA//PBDpv3OmDHj8YMTERERySeeiaScyWRi\nxIgRLF68mDVr1mBjY0Px4sXTHXRQunRpOnbsyPjx4zEMA2tra3r37k2VKlV44403+Oijj7C3t0/3\nPrn7mjVrxrx58x75oIe/2rBhA5GRkZhMJkqXLk3t2rUxmUxYWVmlO+hh+PDhWFtbM3DgQMsBFH/n\n7OxMqVKl0o1ZRERERERERESePSbDMIzcDkL+WWJiIiNGjLAcVvEgLrau94SjEhERkcxYz1ub2yE8\nU/RicMkPNM8lP9A8l7xOBz3kM4cPH2bu3Lm0bt36gRNyIiIiIiIiIiLy9NJKuUxMmTKF2NjYNGVv\nvfUWtWrVyqWIHt6VK1dyOwSRJ0p/hZP8QnNd8gPNc8kPNM8lP9A8l7xOK+VyQEBAQG6HICIiIiIi\nIiIieZRVbgcgIiIiIiIiIiKS3ygpJyIiIiIiIiIiksO0fTUPS+nbLrdDEHmiruZ2AJIjdIKliIiI\niIjkRVopJyIiIiIiIiIiksOUlBMREREREREREclhSsqJiIiIiIiIiIjkMCXlREREHtE333xD8+bN\nadGiBQMHDiQhISHN9a+//ppmzZrh6+tLhw4duHTpEgDh4eH4+flZvipWrMjGjRtzYwgiIiIiIpJL\nlJQTERF5BNHR0SxcuJANGzawefNmUlJSWLNmTZo6Xl5eBAcHExoaSuvWrRk/fjwATZo0ISQkhJCQ\nEIKCgihYsCA+Pj65MQwREREREcklD5WUe/PNNwkICGD48OFMmzaNxMTEJxVXhiIjIzl58uQjt09J\nSaF3794sXbo0G6N6cj766CPL94GBgfTo0YOJEyfmYkQiIvJXycnJJCQkkJyczJ07dyhZsmSa602a\nNKFgwYIA1K1bl+jo6HR9rF+/nubNm1vqiYiIiIhI/vBQSTlbW1umTJnC1KlTMZvNhISEpLluGAap\nqanZGuB9KSkpj52UO3z4MG5ubuzevRvDMDKs86Tiz0hKSkqW1++vqABo164dgwcPftIhiYjIA3ru\nuecYMGAA3t7e1K5dGycnpyxXuy1fvpzmzZunK1+zZg2vvPLKkwxVRERERESeQuZHbejh4UFUVBSx\nsbEEBgZSuXJlzp07x/vvv8/Jkyf54YcfAKhduzZdunQBoGvXrrRs2ZLDhw/j7OzM0KFDcXJyIiYm\nhgULFnDjxg0KFChA//79KVWqFLNmzcLGxoYLFy5QtGhRTp48iZWVFTt27KBXr17MnDmTL774ArPZ\nzO3btwkICLB8zkh4eDgvv/wyISEhnDp1iueffx6AQYMG0ahRI44cOUK7du2oVKlShvHs27eP1atX\nk5ycTKFChRgyZAjOzs4Z3isoKIirV68SExPDzZs3adeuHb6+vkRGRrJixQocHBy4cuUKX3zxBT/+\n+CNbtmwBoEWLFrRu3dryvJYsWQJA9erViYyMzPJnEhoaSmhoKIBW1IlInuHi4pLbIWTo2rVrbNmy\nhVOnTuHs7EynTp34+eef6dy5c7q6y5Yt49ixY4SGhlKgQAFLeXR0NKdOnaJ9+/bY2Nhkei+z2fzU\nPgeR7KJ5LvmB5rnkB5rnIg/ukZJyKSkpHDx4kFq1agEQExPDoEGDqFKlCvHx8SxdupRJkybh4ODA\n+PHj2bt3L97e3iQmJlKpUiV69OjBf//7X1auXEnv3r355ptv6Nu3L8899xynT59m/vz5jB07FoD4\n+HjGjx+PlZUVQUFB2NnZ0a5dOwA8PT05cOAA3t7e7Ny5kwYNGmSakEtKSuLIkSP069eP27dvEx4e\nbknKARQqVIhJkyYB8Omnn2YYj4eHB4GBgZhMJjZt2sTatWvp1q1bps8pKiqKwMBAEhISGDVqFHXq\n1AHg/PnzTJ06FVdXV86dO8eWLVsIDAwE4IMPPqBatWpUqFDhoX8uvr6++Pr6PnQ7EZGnWVxcXG6H\nkKF169ZRsmRJTCYT169fp2XLlmzZsoVWrVqlqbd9+3YCAwNZtWoVN2/e5ObNm5Zr//nPf3jppZe4\nfv16lvdycXF5ap+DSHbRPJf8QPNc8gPNc8nr3Nzcsq2vh0rKJSUlERAQAEDVqlVp0aIF8fHxuLi4\nUKVKFQDOnj2Lp6cnTk5OALz44oscP34cb29vTCYTjRs3tpR//vnnJCQkcPLkSaZNm2a5T3JysuX7\nhg0bYmWV8S7bFi1asHbtWry9vdmyZQv9+/fPNPYDBw7g6emJra0tDRo0YNWqVfTo0cPS9/24soon\nPj6eGTNmcO3aNZKTk3F1dc3yedWrVw9bW1tsbW3x9PTkzJkzODg44O7ubml74sQJvL29sbOzA8Db\n25vjx48/UlJORERyTqlSpThw4AB37tzBzs6OsLAwatasmabO0aNHGT16NN99912GfzH+3//+x/vv\nv59TIYuIiIiIyFPkoZJy998p93f3E0oPy2QykZqaioODQ4b9/lPfHh4eLFiwgMjISFJTUylbtmym\ndcPCwjh58iSDBg0C4ObNmxw9epQaNWoAWLYTZRXPwoULadOmDfXq1SMyMpKVK1f+4/gy+vzXrUsi\nIvJsqlOnDq1bt+all17CbDbj6enJW2+9xZQpU6hZsyatWrXis88+488//7T80ahUqVIsXrwYgIsX\nLxIdHU2jRo1ycRQiIiIiIpJbHuqghwfh7u7OsWPHuHHjBqmpqYSHh1OtWjXg3kEQu3fvBu4lyTw8\nPLC3t8fV1ZVdu3ZZ6ly4cCHDvgsWLEhCQkKasqZNm/Lll19m+PLs+27fvs2JEyeYPXs2s2bNYtas\nWfTu3ZuwsLB0dbOK5/bt2xQtWhSAbdu2/eOziIiIICkpiZs3bxIZGUmlSpXS1fHw8CAiIoLExEQS\nEhKIiIigatWq/9i3iIjkvhEjRrB9+3Y2b97MV199RYECBQgICLBsYV2xYgWHDh0iJCSEkJAQS0IO\noEyZMuzfvz/T1eAiIiIiIpK3PfJBD5kpUqQInTt3Zty4ccC9gx7q168P3FshdubMGVavXo2TkxPv\nvfceAO+88w7z5s2zHKLQpEkTypcvn67vunXrMm3aNCIiIujVqxdVq1blxRdf5Pvvv6dJkyaZxrR3\n7168vLzSvES7fv36fPfdd9y9ezdd/czieeONN5g2bRoODg54eXkRGxub5bMoV64c48aN4+bNm7z+\n+usULVqU6OjoNHUqVqxIs2bN+OCDD4B7W3Lvb13960q7jz/+mMuXL5OQkMCAAQMYMGCA5Z1+IiIi\nIiIiIiLybDEZhmHk1M3+eppodtm9ezcREREMGTIkW/t9XH8/lOJh3bx5k1GjRjF79uxHjuFi63qP\n3FZE5GlhPW9tboeQ6/TCZMkPNM8lP9A8l/xA81zyulw76OFps3DhQn755Zc895Ls+Ph4xo0bR9u2\nbXM7FBEREREREREReQJydKVcTpg/fz4nT55MU+bv75/lO+cex5YtW9iwYUOasueff54+ffo8kfs9\njCtXruR2CCJPlP4KJ/mF5rrkB5rnkh9onkt+oHkueZ1WymUhp5NhzZs3f2IJPxERERERERERyZt0\n5JuIiIiIiIiIiEgOU1JOREREREREREQkh+W57avyf1L6PtrJryLPiqvZ2JdO+BQREREREZGcpJVy\nIiIiIiIiIiIiOUxJORERERERERERkRympJyIiIiIiIiIiEgO0zvlRESecg0aNMDR0RErKyvMZjPB\nwcFpru/cuZNevXpRpkwZAPz9/XnvvfcAGDZsGKGhobi4uLB58+Ycj11EREREREQypqSciMgzYOXK\nlRQtWjTT697e3nz77bfpyjt06EDPnj159913n2R4IiIiIiIi8pCeyPbVN998k4CAAIYNG0ZAQADr\n1q0jNTX1SdzqgQwaNIgbN248Utu9e/dy6dKlbI7owXz00UeW7wMDA+nRowcTJ07MlVhE5NnUsGFD\nnJ2dczsMERERERER+ZsnslLO1taWKVOmAHD9+nW+/PJL7ty5Q4cOHZ7E7Z6oiIgI6tatS+nSpbO9\n75SUFKytrTO9Pn78eMv37dq1IzExkdDQ0GyPQ0SebiaTiU6dOmEymejSpQtdunRJV2f//v34+vpS\nsmRJxowZw/PPP58LkYqIiIiIiMiDeuLbVwsXLky/fv14//33eeONNzAMg6VLl3Ls2DHu3r3LSy+9\nhJ+fH5GRkQQFBWFnZ0dMTAyenp706dMHKysrDh06RFBQEMnJyZQoUYKBAwdiZ2fHoEGD8PHxYf/+\n/SQnJzNs2DBKlSrFzZs3+eKLL4iPj6dKlSoYhmGJZ/v27QQHB5OcnEzlypUt9+jatSv+/v4cOHAA\nW1tbAgICuHr1Kvv27ePYsWOsWrWK4cOHc+DAAUJCQrC2tqZ06dIMHTo0w3EHBQVx9epVYmJiuHnz\nJu3atcPX15fIyEhWrFiBg4MDV65c4YsvvuDHH39ky5YtALRo0YLWrVsD0LVrV5YsWQJA9erViYyM\nzPJZh4aGWpJ2WlEn8nBcXFxyO4RMbdu2jVKlShEbG4u/vz9169blxRdftFxv1qwZZ8+exdHRkeDg\nYPr27cuxY8cs12/duoW1tfVTPUbJmtls1s9P8jzNc8kPNM8lP9A8F3lwOfJOuRIlSpCamsr169fZ\nt28f9vb2TJgwgbt37zJmzBhq1qwJwJkzZ5g2bRrFixcnMDCQvXv3Uq1aNVavXs2YMWOws7Pjf//7\nHz/++CPt27cHoFChQkyaNImffvqJdevWMWDAAFauXImHhwft27fnwIEDlpebX7p0iZ07d/LZZ59h\nNpuZP38+O3bswMfHh8TERCpXrkynTp347rvv2LRpE6+//jr16tWjbt26NGzYEIA1a9Ywc+ZMbGxs\n+PPPP7Mcd1RUFIGBgSQkJDBq1Cjq1KkDwPnz55k6dSqurq6cO3eOLVu2EBgYCMAHH3xAtWrVqFCh\nwkM/Z19fX3x9fR+6nYhAXFxcboeQqQIFChAXF4eVlRV+fn5s27aNqlWrpquXkJBA/fr1SUxM5NSp\nU5Z30F27do2UlJSneoySNRcXF/38JM/TPJf8QPNc8gPNc8nr3Nzcsq2vHD/o4dChQ0RFRbH7/2vv\nzuOqqvM/jr/uBYRAUBQQNzQk3FApkUzDDTAzS5tSU9NfqVMumWmQS7lNmjqIOCW2OJotjpM1TmXa\nT8dyyS1JMRXF3ZFCI8REQkTg/v7w4flJgiLCvcB9Px+PeQxn+57POffT6fH49F127gQgOzubM2fO\n4OjoSEBAAHXq1AGgY8eOJCcn4+TkxE8//cSUKVMAyMvLIzAw0Gjv/vvvB8Df359du3YBcOjQIaKi\nogC47777cHNzA+DAgQOcPHmSSZMmAZCbm4uHhwdwtZrftm1bo619+/YVGb+fnx9vvvkm7dq1IzQ0\n9KbPGhISQrVq1ahWrRotW7bk2LFjuLm5ERAQgI+PDwDJycmEhobi4uICXJ2s/dChQ6UqyolI1ZOd\nnU1BQQHVq1cnOzubzZs3GyurXpOWloa3tzcmk4nExEQKCgrw9PS0UcQiIiIiIiJSElYpyv3yyy+Y\nzWZq1KiBxWLh2WefJTg4uNA5xQ3NtFgstGrVqthhoo6OVx/BbDaTn59/0zgsFgudO3dm4MCBNxxz\ncHDAZDLdsq1JkyZx8OBBdu/ezb///W/mzZtX7Lxw19r747azs/NN4xQRuebXX39l2LBhwNV5KPv0\n6UPXrl2NlVaHDBnCmjVr+PDDD3FwcMDFxYVFixYZ35tRo0axY8cOMjIyaNu2LVFRUQwYMMBmzyMi\nIiIiIiJXlcvqq9fLzMxk8eLF9OjRA5PJRHBwMOvXrycvLw+A1NRUcnJygKvDV9PS0igoKGDHjh00\na9aMwMBADh8+zNmzZ4Grw7NSU1Nves/mzZuzdetWABITE41hpq1atWLnzp1cuHABuDrP0q+//nrT\ntn/RI4gAACAASURBVO666y4uXboEQEFBAenp6QQFBTFo0CCys7ON2IuSkJBAbm4uFy9eJCkpiSZN\nmtxwTrNmzUhISODy5cvk5OSQkJBQ5LA0EbFPjRo1MuaL3LhxI2PHjgWuFuOGDBkCwLPPPsvGjRvZ\nsGEDX331Fe3atTOuX7RoEYmJifz3v/9l9+7dKsiJiIiIiIhUEOXSUy43N5fo6GhjddGwsDB69eoF\nXF3IIC0tjQkTJgDg4eFBdHQ0AAEBASxZssRY6CE0NBSz2czo0aP529/+xpUrVwB46qmnbjqGt2/f\nvvztb39j/PjxBAYGGpNMNmjQgKeeeoqZM2disVhwcHBg2LBheHt7F9tWhw4dePfdd/n666956aWX\nePvtt8nOzgbg4YcfNobGFqVRo0bMmDGDixcv8sQTT1CrVi3OnDlT6Bx/f3+6dOnC5MmTjfdzbejq\n9T3tpk6dys8//0xOTg4jRoxgxIgRN/Q2FBERERERERGRysFkuX5pUhtKSkpi9erVTJw40dahlIlr\nK8k+9thjpbr+4sWLTJgwgUWLFpU6hpRHQkp9rYi9cVj8pa1DECmWJkwWe6A8F3ugPBd7oDyXqq4s\nF3oo9+GrcvsyMjJ47bXXePTRR20dioiIiIiIiIiIlIMK01Oustq4cSNr164ttK9p06YMHz7cRhH9\nv1vNvSdS2em/wom9UK6LPVCeiz1Qnos9UJ5LVVeWPeWssvpqVda1a1e6du1q6zBERERERERERKQS\n0fBVERERERERERERK1NRTkRERERERERExMo0fLUKy/9z6VZ+lfKlVT5FRERERERERD3lRERERERE\nRERErExFOREREREREREREStTUU5ERERERERERMTKNKeciADw888/M3bsWNLT0zGZTAwaNIjhw4cX\nOuftt99m1apVAOTn53P06FH27duHp6cnFy5cICoqisOHD2MymYiNjSUkJMQWjyIiIiIiIiJS4ako\nJyIAODo6Mm3aNFq1akVWVhY9evSgU6dOBAYGGueMHDmSkSNHArB+/XoWL16Mp6cnAFOnTqVr164s\nXryY3NxcLl26ZJPnEBEREREREakMbF6U69+/P35+fsZ2x44d6dOnT6FzkpKSWL16NRMnTiyz+yYl\nJeHo6EjTpk2BqwUGZ2dnOnfuXGb3uFOzZ8/mxRdfxM3NjUWLFrFnzx5q1KhBbGysrUOTKqhOnTrU\nqVMHgOrVq3PPPfdw9uzZQkW5633xxRfGP6uZmZl8//33LFiwAIBq1apRrVo16wQuIiIiIiIiUgnZ\nvChXrVo1YmJirH7fpKQkXFxcjKJc9+7drR6DxWLBYrFgNhc9td+kSZOMv7t06UKPHj2Ij4+3Vnhi\nx1JSUjhw4AD33ntvkccvXbrEpk2bmDlzJgCnT5+mdu3ajBs3joMHD9K6dWv+8pe/4Orqas2wRURE\nRERERCoNmxflirN3716WLVuGs7OzUTgDWLlyJS4uLjz22GMAvPzyy0yYMAEfHx82b97M6tWrMZlM\n+Pn5MWbMGH744QdWrVpFXl4e7u7ujBkzhtzcXP7zn/9gNpv57rvvGDp0KPv37zfaPXXqFIsXL+by\n5cvUqVOHkSNHUr16daZPn05AQABJSUlkZ2czYsQImjdvXmT8mzZtYteuXWRnZ5ORkUFYWBh9+/Yl\nLS2NWbNmcc8993DixAkmTZrE4cOH+fe//w3Avffey9NPPw3A6NGjmT17Nh4eHrRo0YK0tLSbvrMN\nGzawYcMGAObMmXPHv4GUDy8vL1uHcFNZWVmMHDmSuLg47r777iLP+fTTT+nQoQP33HMPAO7u7uzf\nv5+33nqL0NBQxo8fz9KlS5k+fXq5xuro6Fjh36dIWVCuiz1Qnos9UJ6LPVCei5SczYtyubm5REdH\nG9uPP/44ISEhvPvuu0ydOhVfX1/i4uJu2U5KSgqrVq3i9ddfx8PDg6ysLACaNWvGrFmzMJlMfPPN\nN3z55ZcMGTKEyMjIQsW9/fv3G20tXLiQoUOH0qJFCz755BM+++wznnnmGQAKCgqYPXs2e/bs4bPP\nPmPKlCnFxnTs2DFiY2NxdnZm0qRJ3Hfffbi7u3P27FlGjx5NYGAgGRkZLF++nLlz5+Lm5sbMmTPZ\ntWsXoaGht/0uIyIiiIiIuO3rxLrS09NtHUKxrly5wv/8z//w6KOP8uCDDxYb68cff0yvXr2M43fd\ndRd169bF39+f9PR0wsPDWbhwYbk/q5eXV4V+nyJlRbku9kB5LvZAeS72QHkuVV29evXKrC2bF+WK\nGr566tQpfHx8qFu3LgCdOnUyeoAV58CBA7Rv3x4PDw/g6pxYABkZGSxYsIDz58+Tl5eHj4/PTdvJ\nzs7m999/p0WLFgB07ty5UFHwWrHM39//lj3XWrdujbu7u3FdcnIy7dq1w8vLy5in6/jx47Rs2dKI\nOywsjEOHDpWqKCdyJywWCy+//DIBAQE8//zzxZ6XmZnJzp07eeutt4x9Pj4+1KtXj2PHjhEQEMDW\nrVuLnYtORERERERERCpAUe52OTg4YLFYjO3c3Nybnr906VJ69epFSEgISUlJfPrpp3d0fycnJwDM\nZjMFBQW3da3JZALAxcXljmIQKQ8JCQn861//onnz5kRGRgIwceJEfv75ZwCGDBkCwNdff02nTp1u\nmC/u9ddfZ8yYMVy5cgU/Pz/mz59v3QcQERERERERqUQqZFGuXr16pKWlcfbsWXx9fdm6datxzNvb\nmz179gBw4sQJo7daUFAQ8+bNo1evXri7u5OVlUX16tXJzs6mVq1aAGzevNlo56677uLSpUs33NvV\n1ZXq1atz6NAhmjdvzpYtW4qdN+5W9u/fT1ZWFtWqVSMhIYGRI0fecE5AQADvv/8+mZmZVK9enW3b\nttGjR49S3U/kToSGhhoFuJvp378//fv3v2F/UFAQX3/9dXmEJiIiIiIiIlLl2Lwo98c55YKDgxk0\naBDPP/88c+bMwdnZmWbNmpGTkwNA+/bt2bJlC+PHjycgIMAYy9uwYUMef/xxpk+fjtlspnHjxowe\nPZq+ffsyf/583NzcCAoKMop4bdu2Zf78+SQkJDB06NBCMY0ePdpY6MHHx4dRo0aV6tmaNGlCbGws\n586dIywsjCZNmtww5NXT05OBAwcyY8YM4OpCD+3atTOOX+tdt2DBAg4ePMjFixcZMWIE/fr1o1u3\nbqWKS0REREREREREbMtkuX4sqJSZTZs2cfz4cYYNG1aq6wsKChg+fDjvvfcejo6lq52mPBJSquuk\nfDks/tLWIVQZmkRW7IVyXeyB8lzsgfJc7IHyXKq6slzowVxmLUmZGj9+PN26dSt1QU5ERERERERE\nRCouVXzu0N69e1m+fHmhfT4+PkRHR9OlS5dSt7tgwYI7jEw9skREREREREREKioV5e5QcHAwwcHB\ntg5DREREREREREQqEQ1fFRERERERERERsTIV5URERERERERERKxMw1ersPw/P3bHbWheOhERERER\nERGRsqeeciIiIiIiIiIiIlamopyIiIiIiIiIiIiVqSgnIiIiIiIiIiJiZSrKSaW1ceNGwsLC6Nix\nIwsXLiz2vDVr1lC/fn1+/PFHAHJzcxk3bhzh4eFERESwfft2a4UsIiIiIiIiIgJooQeppPLz83n1\n1VdZsWIFdevWpWfPnnTv3p3AwMBC52VlZbFkyRLuvfdeY98//vEPAL755hvS09N5+umnWbt2LWaz\natQiIiIiIiIiYh0lqkKsWrWK8ePHExUVRXR0NEePHi323Pj4eHbu3AnAoUOHGD9+PNHR0eTm5t5w\nblpaGoMGDSI6Otr43+bNm0v5KIUNHjy4TNopzvXPWR5++OEHPv/8cwAOHjzIhAkTeOqpp8r1npVJ\nYmIijRs3plGjRlSrVo3evXuzbt26G87761//yqhRo3BxcTH2HTlyhI4dOwLg5eWFh4eH0YtORERE\nRERERMQabtlT7siRI+zevZu5c+fi5OREZmYmeXl5JWr8u+++o0+fPnTq1KnYc3x9fYmJiSl5xFVI\nfn4+Dg4ORR4LCQkhJCQEuFo4GjVqFKtXr7ZmeBXa2bNnqVevnrFdt25dEhMTC52zf/9+zpw5Q0RE\nBO+8846xv0WLFqxfv54+ffqQmprK/v37SU1NLdSbTkRERERERESkPN2yKHf+/Hnc3d1xcnICwMPD\nA4ATJ07wwQcfkJOTg4eHB6NGjcLT09O47ptvvmHHjh38+OOP7N27lxdffPG2Ahs8eDDdu3cnMTER\nT09PBgwYwMcff0x6ejrPPPMMISEhbNq0iV27dpGdnU1GRgZhYWH07du3UDsWi4WPP/6YvXv3AvDE\nE0/QoUMHFi5cSGhoKKGhoQC8+eabPPDAA7Rt25bly5dz8OBBrly5wkMPPURkZCQWi4WlS5eyb98+\nvLy8cHS8+asbPXo0DzzwAImJiVSrVo2xY8fi6+tLfHw8Tk5OnDp1iqZNm/LEE0+waNEi0tLScHZ2\n5rnnnqNRo0Zs2rSJ48ePM2zYMHx8fAAwmUy39Q7tWUFBATNmzCAuLu6GY0899RRHjx7l4YcfpkGD\nBoSEhBRbHBURERERERERKQ+3LMq1adOGzz77jLFjx9KqVSs6dOhAYGAgS5cu5ZVXXsHDw4Pt27ez\nYsUKRo0aZVwXHh5OcnIybdu2pX379sW2f/bsWaKjo43toUOH0rx5cy5fvkxQUBCDBw8mJiaGf/7z\nn7z22mv89NNPxMfHG73Ijh07RmxsLM7OzkyaNIn77ruPJk2aGO19//33nDp1ipiYGDIzM5k0aRLN\nmzenW7dufPXVV4SGhpKdnc3hw4cZPXo03377La6ursyePZsrV64wZcoU2rRpw8mTJ0lNTSUuLo7f\nfvuN8ePH07Vr15u+O1dXV2JjY9m8eTPLli1j4sSJAGRkZDBz5kzMZjNLly7l7rvv5pVXXuHAgQMs\nXLiw1D0HN2zYwIYNGwCYM2dOqdr4Iy8vrzJpp6w1a9aMTz/91IgvMzOTJk2aGNsXLlzgyJEj9O/f\nH7iaZ8OGDeNf//oXbdu2JT4+3mirc+fOtG3btsI+qxTP0dFRv5vYBeW62APludgD5bnYA+W5SMnd\nsijn4uLC3LlzOXToEElJScTFxfHEE0+QkpLC66+/DlztlXR9L7nbUdzwVUdHR4KDgwHw8/PDyckJ\nR0dH/Pz8+PXXX43zWrdujbu7OwChoaEkJycXKsolJyfTsWNHzGYzNWvWpEWLFhw/fpyQkBD+/ve/\nk5mZyc6dO7n//vtxcHDgxx9/5PTp08bcbdnZ2Zw5c4ZDhw4Z7dSqVYugoKBbPtu1ecs6duzIBx98\nYOxv3769sahAcnIyL7/8MgBBQUFkZWWRnZ19W+/wmoiICCIiIkp1bXHS09PLtL2y0rhxY44cOcKe\nPXvw9fXlH//4B/Hx8YXi3bdvn/H3k08+yZQpU2jUqBEpKSlYLBZcXV3ZsmULFosFb2/vCvusUjwv\nLy/9bmIXlOtiD5TnYg+U52IPlOdS1V0/ldadKtHqq2azmZYtW9KyZUv8/PxYt24dDRo0YNasWWUW\nyB85ODgYwzVNJpMxXNRsNpOfn1/sdbczxLNTp05s2bKF7du3G738LBYLzz77rFEQvOaP85WVxPWx\nXP/39YsOSOk4Ojoyc+ZMBg4cSEFBAf3796dp06bExMTQpk0bunfvXuy16enpDBw4ELPZjK+vL2++\n+aYVIxcRERERERERKcHqq6mpqZw5c8bYPnXqFPXr1yczM5MjR44AkJeXR0pKSvlFeRP79+8nKyuL\n3NxcEhISaNq0aaHjzZs3Z8eOHRQUFJCZmcmhQ4cICAgAoEuXLqxduxaABg0aABAcHMz69euNxSxS\nU1PJyckp1M758+dJSkq6ZWzbt283/v+ee+4p8pxmzZrx3XffAZCUlIS7uzuurq6leBP2Jzw8nK1b\nt7J9+3bGjh0LQHR0dJEFuc8++4w2bdoA0LBhQ7777js2b97MJ598Yvz2IiIiIiIiIiLWcsuecjk5\nOSxdupTff/8dBwcHfH19ee6554iIiOD9998nOzub/Px8evbsScOGDW87gD/OKde1a1d69uxZ4uub\nNGlCbGws586dIywsrNDQVbg6pPXIkSPGPZ5++mlq1qwJQM2aNalfvz7t2rUzzu/WrRtpaWlMmDAB\nuLqwRXR0NKGhoRw4cIBx48bh5eVFYGDgLWPLysoiKioKJycno2j0R/369WPRokVERUXh7OzM6NGj\njWPXetcdO3aMefPm8fvvv7N7925WrlzJ/PnzS/yORERERERERESkYjFZLBaLrYMoretXKC2Ny5cv\nExUVxdy5c8u8d9ro0aOZPXu2sVrt7Vq9ejWXLl2iX79+pY4h5ZGQUl97jcPiL++4DZHyovkqxF4o\n18UeKM/FHijPxR4oz6WqK8s55W45fLWq2rdvH+PGjaNHjx4Vbrjo+vXr2bRpE2FhYbYORURERERE\nREREyoFVesqdPn2at956q9A+Jycn3njjjfK+dbmLiYkhLS2t0L5BgwbdsFCELainnFR1+q9wYi+U\n62IPlOdiD5TnYg+U51LVlWVPuUo9fFVuLjU11dYhiJQr/Qtf7IVyXeyB8lzsgfJc7IHyXKo6DV8V\nERERERERERGpxFSUExERERERERERsTIV5URERERERERERKzM0dYBSPnJ//NjJT5XCzqIiIiIiIiI\niFiPesqJiIiIiIiIiIhYmYpyIiIiIiIiIiIiVqainIiIiIiIiIiIiJWpKCcV3saNGwkLC6Njx44s\nXLjwhuMffvgh4eHhREZG0qdPH44cOQLAli1b6NGjB+Hh4fTo0YOtW7daO3QRERERERERkSKVaqGH\nwYMH89FHH5V1LLe0a9cu5s2bR1xcHPXr17f6/a9Zs2YNERERODs7F3l88uTJXLlyhaysLHJzc6lV\nqxYA0dHR+Pj4WDPUSi8/P59XX32VFStWULduXXr27En37t0JDAw0znn88ccZMmQIAOvXr2fGjBks\nX76cWrVqsWzZMnx9fUlOTmbQoEHs3r3bVo8iIiIiIiIiImKoVKuvbtu2jWbNmrFt2zb69etnszjW\nrl1LWFhYsUW5N954A4BNmzZx/Phxhg0bdlvt5+fn4+DgcMdxVgWJiYk0btyYRo0aAdC7d2/WrVtX\nqCjn7u5u/J2dnY3JZAIgKCjI2N+0aVNycnK4fPlysb+biIiIiIiIiIi1lFlRLi0tjbfffpuLFy/i\n4eHBqFGj8PLy4ocffmDVqlXk5eXh7u7OmDFjqFmzJitXriQ9PZ20tDTS09Pp2bMnPXv2LLb9nJwc\nkpOTmTZtGnPnzjWKcklJSaxcuRI3NzdOnz7NAw88gJ+fH2vXriU3N5fo6Gh8fX2LjS8+Pp62bdvS\nvn174P97ASYlJfHpp5/i7u5OSkoK/v7+jBkzhq+//pqMjAxmzJiBh4cH06ZNu633lJiYyGeffUZe\nXh6+vr6MHDkSFxcXRowYQVhYGD/++COPP/44a9euJSAggEOHDnH58mVeeOEFVq1aRUpKCg8++KBN\ni5LWdPbsWerVq2ds161bl8TExBvOW7ZsGe+99x65ubmsXLnyhuNr1qwhKChIBTkRERERERERqRDK\nrCi3dOlSOnfuTJcuXfj2229ZunQpr7zyCs2aNWPWrFmYTCa++eYbvvzyS2OoYWpqKtOmTePSpUu8\n9NJLdO/eHUfHokNKSEggODiYevXq4e7uzokTJ/D39wfgv//9L3FxcVSvXp0XXniB8PBwZs+ezdq1\na/nf//1fnnnmmWLju5mTJ08yf/58PD09mTJlCocPH6Znz56sWbOGadOm4eHhcVvv6MKFC3z++edM\nnToVZ2dnVq1axdq1a/nTn/4EQI0aNfjrX/8KXO2NV61aNebMmcPq1auJiYlhzpw5uLq6MmbMGB55\n5BHc3NwKtb9hwwY2bNgAwJw5c24rNi8vr9s631o8PDxwcXEx4nN3dy+0fU1UVBRRUVH885//5N13\n32XJkiXGsYMHDzJnzhzWrFlTYZ9TSsfR0VG/qdgF5brYA+W52APludgD5blIyZVZUe7o0aNERUUB\n0KlTJ5YvXw5ARkYGCxYs4Pz58+Tl5RWaU+2+++7DyckJJycnatSowYULF6hdu3aR7W/bts3oSdeh\nQwe2bt1qFOWaNGmCp6cnAL6+vrRu3RoAPz8/Dhw4cNP4biYgIMCIp3HjxqSlpdGsWbPbezHXOXz4\nMD/99BOvvfYaAHl5eYXa69ChQ6HzQ0JCjOfw8/OjZs2aAHh7e3Pu3LkbinIRERFERESUKrb09PRS\nXVfeXF1dOXHihBHfkSNHqFmzZrHxduvWjRdeeIG5c+cCVwu//fr1Iy4ujho1alTY55TS8fLy0m8q\ndkG5LvZAeS72QHku9kB5LlXd9aP57lS5zym3dOlSevXqRUhIiDEk1Lj5db3izGYz+fn5RbaRlZXF\ngQMHOH36NCaTiYKCAuDqUFMAJycn41yTyWRsX39ucRwcHIxzCgoKyMvLM45d367ZbL5lWyURHBzM\nmDFjijz2x6GV1z/H9e+qJM9VVQQHB3Py5ElOnz6Nr68vX3zxBfHx8YXOub7X5IYNG7j77ruBqz0T\nhwwZwuTJk2nXrp3VYxcRERERERERKY65rBoKDAxk+/btAGzdutXoAZadnW2sPrp58+ZStb1z5046\nderEokWLiI+P5+2338bHx4dDhw7dcXze3t6cOHECgB9++KHYwuD1XFxcyMnJue3nCAwM5ODBg/zy\nyy/A1Xnyzpw5c9vt2BNHR0dmzpzJwIED6dKlC48++ihNmzYlJiaG9evXA1fnk+vatSuRkZG89957\nLFiwAID333+fU6dOERcXR2RkJJGRkfovNiIiIiIiIiJSIZSqp1xubi4jRowwtnv16sXQoUNZtGgR\nX375pbGQAkDfvn2ZP38+bm5uBAUFkZaWdtv327ZtG7179y607/7772fbtm03DPksTnHxhYeHExMT\nQ3R0NG3atCnRQgARERHMmjWLWrVq3dZCDzVr1mTkyJEsWLDA6JE3YMAA6tatW+I27FF4eDjh4eGF\n9kVHRxt//+UvfynyupdeeomXXnqpXGMTERERERERESkNk8Visdg6CCkfKY+ElPhch8VflmMkIuVD\n81WIvVCuiz1Qnos9UJ6LPVCeS1VXlnPKldnwVRERERERERERESmZcl/o4XZcvHixyKGIU6dOxd3d\n3QYR3drkyZO5cuVKoX1jxozBz8/PRhGJiIiIiIiIiEhFp+GrVVhqaqqtQxApV+oaL/ZCuS72QHku\n9kB5LvZAeS5VnYavioiIiIiIiIiIVGIqyomIiIiIiIiIiFiZinIiIiIiIiIiIiJWVqEWepCylf/n\nx27Y57D4SxtEIiIiIiIiIiIi11NPOREREREREREREStTUU5ERERERERERMTKVJQTERERERERERGx\nMhXlpMLYuHEjYWFhdOzYkYULF95wfOfOnTz00EP4+fnx1VdfFTr2888/M2DAADp37kyXLl1ISUmx\nVtgiIiIiIiIiIrdNCz1IhZCfn8+rr77KihUrqFu3Lj179qR79+4EBgYa59SvX5+4uDjeeeedG64f\nO3YsL774Ip06deL333/HbFa9WUREREREREQqrkpZlPvtt9/44IMPOHr0KG5ubjg6OtK7d29CQ0Pv\nqN2kpCRWr17NxIkTyyjS0nvnnXfo1asXDRo0YMWKFWzZsoWsrCw++ugjW4dWLhITE2ncuDGNGjUC\noHfv3qxbt65QUa5hw4YANxTcjhw5Ql5eHp06dQLAzc3NSlGLiIiIiIiIiJROpSvKWSwWYmJi6Ny5\nM2PHjgXg119/5YcffrB6LPn5+Tg4OJT6+oKCgmJ7dI0YMcL4u23btvTo0YMXX3yx1Peq6M6ePUu9\nevWM7bp165KYmFiia0+cOIGHhwfDhw/n9OnThIWFMXny5Dv6bUREREREREREylOlK8odOHAAR0dH\nunfvbuzz9vbm4YcfpqCggOXLl3Pw4EGuXLnCQw89RGRkJElJSXz66ae4u7uTkpKCv78/Y8aMwWQy\nsXfvXpYtW4azszNNmzY12szJyWHp0qWkpKSQn59P3759adeuHZs2beL7778nJyeHgoICZsyYcUOM\nSUlJrFy5EhcXF86ePUvLli0ZPnw4ZrOZwYMHExkZyf79+xk2bBhXrlzho48+Ij8/nyZNmvDnP/8Z\nJycnpk+fzuDBg2nSpEmh3mI3s2HDBjZs2ADAnDlzijzHy8vrdl631Xh4eODi4mLE5+7uXmj7ei4u\nLnh4eBjHXF1dSUhI4Pvvv8fPz49Bgwaxdu1ann32Was+g1ifo6Njhc1pkbKkXBd7oDwXe6A8F3ug\nPBcpuUpXlEtJSeHuu+8u8ti3336Lq6srs2fP5sqVK0yZMoU2bdoAcPLkSebPn4+npydTpkzh8OHD\n+Pv78+677zJ16lR8fX2Ji4sz2lq1ahVBQUGMGjWK33//ncmTJ9OqVSujrXnz5lG9evVi4zx27Bjz\n58/H29ubWbNmsWvXLtq3b8/ly5cJCAhgyJAh5ObmMnbsWKZMmUK9evVYuHAh69ev55FHHinVu4mI\niCAiIuKm56Snp5eq7fLm6urKiRMnjPiOHDlCzZo1i4w3JyeHzMxM45ibmxstWrTAw8OD3377ja5d\nu7Jjxw4effRRqz6DWJ+Xl1eFzWmRsqRcF3ugPBd7oDwXe6A8l6ru+lF+d6rSFeX+6O9//zuHDx82\nqvGnT59m586dAGRnZ3PmzBkcHR0JCAigdu3aADRu3Ji0tDRcXFzw8fGhbt26AHTq1MnoabZv3z52\n797N6tWrAcjNzTU+LK1bt75pQQ4gICCAOnXqANCxY0eSk5Np3749ZrOZ9u3bA5CamoqPj4/xg3bu\n3Jl169aVuihXmQUHB3Py5ElOnz6Nr68vX3zxBfHx8SW+9sKFC5w7d47atWuzbds2oxgrIiIiDvEI\nyAAAB6VJREFUIiIiIlIRVbqiXMOGDfn++++N7eHDh5OZmcmkSZOoXbs2zz77LMHBwYWuSUpKwsnJ\nydg2m80UFBTc9D4Wi4WXX375hgrosWPHcHZ2LnX8Tk5OWhm0CI6OjsycOZOBAwdSUFBA//79adq0\nKTExMbRp04bu3buzd+9ehg0bxoULF/jPf/5DbGwsGzduxMHBgalTp9K/f38sFgutWrVi4MCBtn4k\nEREREREREZFiVbqiXFBQECtWrGD9+vXGvHK5ubnA1R5T69evJygoCEdHR1JTU6lVq1axbdWrV4+0\ntDTOnj2Lr68vW7duNY61adOGr7/+mqFDh2IymTh58mSxw2aLcuzYMdLS0vDy8mLHjh2Eh4ff8v5b\ntmyhRYsWJb5HVRMeHn7De4qOjjb+Dg4OZvfu3UVee30vRxERERERERGRiq7SFeVMJhPR0dF88MEH\nfPHFF8YCAYMGDaJ9+/akpaUxYcIE4OriAdcXdf6oWrVqPP/888yZMwdnZ2eaNWtGTk4OAE8++STL\nli0jKioKi8WCj48PEydOLHGcAQEBLFmyxFjoITQ0tMj7jxo1ivnz5xsLPURGRhZ6VoCPP/6YrVu3\nkpuby4gRI+jWrRv9+vUrcSwiIiIiIiIiIlKxmCwWi8XWQVQ1SUlJrF69+raKeH/08ssvM2HCBHx8\nfErdRsojITfsc1j8ZanbE6loNIms2AvlutgD5bnYA+W52APluVR1ZbnQgyY3q4Bef/11/Pz87qgg\nJyIiIiIiIiIiFVelG75akZw+fZq33nqr0D4nJyfeeOMNWrZsWep2p0yZcqehAeoVJyIiIiIiIiJS\nUakodwf8/PyIiYmxdRgiIiIiIiIiIlLJaPiqiIiIiIiIiIiIlakoJyIiIiIiIiIiYmUqyomIiIiI\niIiIiFiZinIiIiIiIiIiIiJWpqKciIiIiIiIiIiIlakoJyIiIiIiIiIiYmUqyomIiIiIiIiIiFiZ\ninIiIiIiIiIiIiJWZrJYLBZbByEiIiIiIiIiImJP1FOuipo4caKtQxApd8pzsRfKdbEHynOxB8pz\nsQfKc5GSU1FORERERERERETEylSUExERERERERERsTKH6dOnT7d1EFI+/P39bR2CSLlTnou9UK6L\nPVCeiz1Qnos9UJ6LlIwWehAREREREREREbEyDV8VERERERERERGxMhXlRERERERERERErMzR1gFI\n2du7dy/vv/8+BQUFhIeH06dPH1uHJFLmRo8ejYuLC2azGQcHB+bMmWPrkETu2KJFi9izZw81atQg\nNjYWgKysLOLi4vj111/x9vZm3LhxVK9e3caRityZonJ95cqVfPPNN3h4eAAwYMAA7rvvPluGKXJH\n0tPTiY+P57fffsNkMhEREUHPnj31XZcqpbg81zddpGRUlKtiCgoKWLJkCa+99hq1a9dm0qRJhISE\n0KBBA1uHJlLmpk2bZvyLXqQq6NKlCz169CA+Pt7Y9/nnn9OqVSv69OnD559/zueff87TTz9twyhF\n7lxRuQ7wyCOP8Nhjj9koKpGy5eDgwODBg/H39+fSpUtMnDiR1q1bs2nTJn3XpcooLs9B33SRktDw\n1Srm2LFj+Pr6UqdOHRwdHenQoQMJCQm2DktEREqgRYsWN/SWSEhIoHPnzgB07txZ33SpEorKdZGq\nxtPT01iB8q677qJ+/fpkZGTouy5VSnF5LiIlo55yVUxGRga1a9c2tmvXrs3Ro0dtGJFI+Zk1axYA\nkZGRRERE2DgakfJx4cIFPD09AahZsyYXLlywcUQi5WfdunVs2bIFf39/hgwZosKdVBlpaWmcPHmS\ngIAAfdelyro+z5OTk/VNFykBFeVEpFJ6/fXXqVWrFhcuXGDmzJnUq1ePFi1a2DoskXJlMpkwmUy2\nDkOkXHTv3p0nn3wSgE8++YQPP/yQUaNG2TgqkTuXk5NDbGwszzzzDK6uroWO6bsuVcUf81zfdJGS\n0fDVKqZWrVqcO3fO2D537hy1atWyYUQi5eNaXteoUYN27dpx7NgxG0ckUj5q1KjB+fPnATh//rzm\nUZQqq2bNmpjNZsxmM+Hh4Rw/ftzWIYncsby8PGJjYwkLC+P+++8H9F2XqqeoPNc3XaRkVJSrYpo0\nacKZM2dIS0sjLy+P7du3ExISYuuwRMpUTk4Oly5dMv7et28ffn5+No5KpHyEhISwefNmADZv3ky7\ndu1sHJFI+bhWpADYtWsXDRs2tGE0InfOYrHwzjvvUL9+fXr16mXs13ddqpLi8lzfdJGSMVksFout\ng5CytWfPHj744AMKCgro2rUrf/rTn2wdkkiZ+uWXX5g3bx4A+fn5PPjgg8pzqRIWLFjAwYMHuXjx\nIjVq1KBfv360a9eOuLg40tPT8fb2Zty4cZqTRSq9onI9KSmJU6dOYTKZ8Pb25rnnnjPm3RKpjJKT\nk5k6dSp+fn7GENUBAwZwzz336LsuVUZxeb5t2zZ900VKQEU5ERERERERERERK9PwVRERERERERER\nEStTUU5ERERERERERMTKVJQTERERERERERGxMhXlRERERERERERErExFOREREREREREREStTUU5E\nRERERERERMTKVJQTERERERERERGxsv8DPP3JhDKqeOIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7480be7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predicting...\n",
      "CPU time: 0.0455470085144043 seconds\n",
      "\n",
      "top 10 predictions :\n",
      "\n",
      "          N         Y Loan_Status_predicted\n",
      "0  0.179763  0.820237                     Y\n",
      "1  0.099094  0.900906                     Y\n",
      "2  0.202356  0.797644                     Y\n",
      "3  0.169629  0.830371                     Y\n",
      "4  0.339059  0.660941                     Y\n",
      "5  0.236936  0.763064                     Y\n",
      "6  0.241377  0.758623                     Y\n",
      "7  0.878068  0.121932                     N\n",
      "8  0.243784  0.756216                     Y\n",
      "9  0.089693  0.910307                     Y\n",
      "\n",
      "dumping predictions into directory : save\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor().fit_predict(best, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.read_csv(os.path.join(predictor.get_params()['to_path'], \"{}_predictions.csv\".format(target_name)))\n",
    "predictions_df.columns = predictions_df.columns.str.replace('_predicted', '')\n",
    "\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "solution_df = pd.DataFrame({\n",
    "    'Loan_ID': test_data['Loan_ID'].values,\n",
    "    target_name: predictions_df[target_name].values\n",
    "})\n",
    "\n",
    "def build_solution_file(filename, dataframe, tag=''):\n",
    "    dataframe.to_csv(filename, index=False, quoting=csv.QUOTE_ALL)\n",
    "    zipf = zipfile.ZipFile('submission_{}.zip'.format(tag), 'w', zipfile.ZIP_DEFLATED)\n",
    "    zipf.write(filename)\n",
    "    zipf.close()\n",
    "    \n",
    "timetag = format(pd.Timestamp.utcnow().tz_convert('Europe/Paris'), '%Y%m%d%H%M%S')\n",
    "filename = \"./result_{}.csv\".format(timetag)\n",
    "\n",
    "build_solution_file(filename, solution_df, tag=timetag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "score = 0.791667"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
